[
  {
    "objectID": "setup/index.html",
    "href": "setup/index.html",
    "title": "Setting up",
    "section": "",
    "text": "Please follow CASA0013 Set-up page to set up the CASA Computing Environment."
  },
  {
    "objectID": "setup/index.html#set-up",
    "href": "setup/index.html#set-up",
    "title": "Setting up",
    "section": "",
    "text": "Please follow CASA0013 Set-up page to set up the CASA Computing Environment."
  },
  {
    "objectID": "sessions/weekX_lecture.html#understanding-and-describing-data",
    "href": "sessions/weekX_lecture.html#understanding-and-describing-data",
    "title": "XXX",
    "section": "Understanding and describing data",
    "text": "Understanding and describing data\n\nQuantitative research is the process of collecting and analysing numerical data to describe, model, and predict variables of interest.\nGarbage in, garbage out.\n\n\nThis lecture focuses on understanding and describing data."
  },
  {
    "objectID": "sessions/weekX_lecture.html#learning-objectives",
    "href": "sessions/weekX_lecture.html#learning-objectives",
    "title": "XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nUnderstand basic data types;\nConsider how to summarise and represent data."
  },
  {
    "objectID": "sessions/week9.html",
    "href": "sessions/week9.html",
    "title": "Week 9",
    "section": "",
    "text": "This week will introduce how to simplify complex datasets by reducing the number of variables while preserving important information.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#introduction",
    "href": "sessions/week9.html#introduction",
    "title": "Week 9",
    "section": "",
    "text": "This week will introduce how to simplify complex datasets by reducing the number of variables while preserving important information.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#learning-objectives",
    "href": "sessions/week9.html#learning-objectives",
    "title": "Week 9",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nUnderstand the principle of dimensionality reduction.\nUnderstand the method of principle component analysis.\nVisualise and describe the results of PCA.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#lecture",
    "href": "sessions/week9.html#lecture",
    "title": "Week 9",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#quiz",
    "href": "sessions/week9.html#quiz",
    "title": "Week 9",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#practical",
    "href": "sessions/week9.html#practical",
    "title": "Week 9",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week9.html#further-resources",
    "href": "sessions/week9.html#further-resources",
    "title": "Week 9",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "9. Dimension Reduction"
    ]
  },
  {
    "objectID": "sessions/week8_lecture.html#understanding-and-describing-data",
    "href": "sessions/week8_lecture.html#understanding-and-describing-data",
    "title": "XXX",
    "section": "Understanding and describing data",
    "text": "Understanding and describing data\n\nQuantitative research is the process of collecting and analysing numerical data to describe, model, and predict variables of interest.\nGarbage in, garbage out.\n\n\nThis lecture focuses on understanding and describing data."
  },
  {
    "objectID": "sessions/week8_lecture.html#learning-objectives",
    "href": "sessions/week8_lecture.html#learning-objectives",
    "title": "XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nUnderstand basic data types;\nConsider how to summarise and represent data."
  },
  {
    "objectID": "sessions/week7_practical.html",
    "href": "sessions/week7_practical.html",
    "title": "Practical XXX: XXX",
    "section": "",
    "text": "This week is focussed on XXX."
  },
  {
    "objectID": "sessions/week7_practical.html#to-add-a-callout-note",
    "href": "sessions/week7_practical.html#to-add-a-callout-note",
    "title": "Practical XXX: XXX",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nSuggestions for a Better Learning Experience:\n\nXXX"
  },
  {
    "objectID": "sessions/week7_practical.html#to-add-python-code-without-running-them",
    "href": "sessions/week7_practical.html#to-add-python-code-without-running-them",
    "title": "Practical XXX: XXX",
    "section": "To add Python code without running them …",
    "text": "To add Python code without running them …\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())"
  },
  {
    "objectID": "sessions/week7_practical.html#to-add-and-run-python-code",
    "href": "sessions/week7_practical.html#to-add-and-run-python-code",
    "title": "Practical XXX: XXX",
    "section": "To add and run Python code",
    "text": "To add and run Python code\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2"
  },
  {
    "objectID": "sessions/week7_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "href": "sessions/week7_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "title": "Practical XXX: XXX",
    "section": "To add a photo - replace the path. Using relative path is also okay.",
    "text": "To add a photo - replace the path. Using relative path is also okay."
  },
  {
    "objectID": "sessions/week7_practical.html#to-add-some-questions",
    "href": "sessions/week7_practical.html#to-add-some-questions",
    "title": "Practical XXX: XXX",
    "section": "To add some “questions”",
    "text": "To add some “questions”\nThe qmd file will be rendered as two files in sessions folder, including a html and ipynb format. The html file will contain both question and answer, while the ipynb file will contain only the question.\nFor the effect, please check HTML and ipynb.\n\nQuestionAnswerAnswer\n\n\nif ??\n    ??\nelse:\n    ??\n\n\n\n\n\nif 'Moscow' in ['Moscow', 'Beijing']:\n    print(\"Moscow is in the cities list.\")\nelse:\n    print(\"Moscow is not in the cities list.\")\nMoscow is in the cities list."
  },
  {
    "objectID": "sessions/week7_practical.html#youre-done",
    "href": "sessions/week7_practical.html#youre-done",
    "title": "Practical XXX: XXX",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/week7.html",
    "href": "sessions/week7.html",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#introduction",
    "href": "sessions/week7.html#introduction",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#learning-objectives",
    "href": "sessions/week7.html#learning-objectives",
    "title": "Week XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nXXX\nXXX\nXXX",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#lecture",
    "href": "sessions/week7.html#lecture",
    "title": "Week XXX",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#quiz",
    "href": "sessions/week7.html#quiz",
    "title": "Week XXX",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#practical",
    "href": "sessions/week7.html#practical",
    "title": "Week XXX",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week7.html#further-resources",
    "href": "sessions/week7.html#further-resources",
    "title": "Week XXX",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "7. Generalised Linear Regression"
    ]
  },
  {
    "objectID": "sessions/week6_lecture.html#understanding-and-describing-data",
    "href": "sessions/week6_lecture.html#understanding-and-describing-data",
    "title": "XXX",
    "section": "Understanding and describing data",
    "text": "Understanding and describing data\n\nQuantitative research is the process of collecting and analysing numerical data to describe, model, and predict variables of interest.\nGarbage in, garbage out.\n\n\nThis lecture focuses on understanding and describing data."
  },
  {
    "objectID": "sessions/week6_lecture.html#learning-objectives",
    "href": "sessions/week6_lecture.html#learning-objectives",
    "title": "XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nUnderstand basic data types;\nConsider how to summarise and represent data."
  },
  {
    "objectID": "sessions/week5.html",
    "href": "sessions/week5.html",
    "title": "Week 5",
    "section": "",
    "text": "This week, we’ll explore how to tell if several groups are truly different and how to measure the strength and direction of the relationship between two variables.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#introduction",
    "href": "sessions/week5.html#introduction",
    "title": "Week 5",
    "section": "",
    "text": "This week, we’ll explore how to tell if several groups are truly different and how to measure the strength and direction of the relationship between two variables.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#learning-objectives",
    "href": "sessions/week5.html#learning-objectives",
    "title": "Week 5",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nUnderstand ANOVA.\nUnderstand correlation between two variables.\nUnderstand the difference of Pearson and Spearman correlation.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#lecture",
    "href": "sessions/week5.html#lecture",
    "title": "Week 5",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#quiz",
    "href": "sessions/week5.html#quiz",
    "title": "Week 5",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#practical",
    "href": "sessions/week5.html#practical",
    "title": "Week 5",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week5.html#further-resources",
    "href": "sessions/week5.html#further-resources",
    "title": "Week 5",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "5. Measuring Relationship"
    ]
  },
  {
    "objectID": "sessions/week4_lecture.html#overview-of-lecture-3",
    "href": "sessions/week4_lecture.html#overview-of-lecture-3",
    "title": "Linear Algebra",
    "section": "Overview of lecture 3",
    "text": "Overview of lecture 3\nLooked at hypothesis testing:\n\nWhat makes a good hypothesis\nHow to formally state a hypothesis\nTypes of statistical tests"
  },
  {
    "objectID": "sessions/week4_lecture.html#back-to-the-start",
    "href": "sessions/week4_lecture.html#back-to-the-start",
    "title": "Linear Algebra",
    "section": "Back to the start",
    "text": "Back to the start\nMaths underpins quantitative methods\n\nquantitative methods includes data analysis and machine learning\nfocused on algorithms and methodologies\nAND practical examples of how these can be applied"
  },
  {
    "objectID": "sessions/week4_lecture.html#maths-underpins-it",
    "href": "sessions/week4_lecture.html#maths-underpins-it",
    "title": "Linear Algebra",
    "section": "Maths underpins it",
    "text": "Maths underpins it\n\n\n\n\n\nImage credit: [xkcd](https://xkcd.com/1838/)\n\n\n\n\nThis lecture covers some of the key concepts.\nThe goal is to facilitate deeper understanding of the methods."
  },
  {
    "objectID": "sessions/week4_lecture.html#maths-doesnt-bite",
    "href": "sessions/week4_lecture.html#maths-doesnt-bite",
    "title": "Linear Algebra",
    "section": "Maths doesn’t bite!",
    "text": "Maths doesn’t bite!\n\n\n\n\nMaths can seem scary – but goal is to have a better understanding of key ideas. Going to cover quite abit - so focus on the goal of being able to understand equations.\nNot expecting students to be experts!"
  },
  {
    "objectID": "sessions/week4_lecture.html#learning-objectives",
    "href": "sessions/week4_lecture.html#learning-objectives",
    "title": "Linear Algebra",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nDefine concept of linear maps.\nCompute linear algebra equations using vectors and matrices.\n\nDescribe how linear algebra relates to solving linear regression."
  },
  {
    "objectID": "sessions/week4_lecture.html#what-does-it-mean",
    "href": "sessions/week4_lecture.html#what-does-it-mean",
    "title": "Linear Algebra",
    "section": "What does it mean?",
    "text": "What does it mean?\nThe goal is to understand equations like this:\n\\[\\begin{align}\ny = \\sum_{i=1}^n \\beta_i x_i\n\\end{align}\\]\n\nThis is a linear equation."
  },
  {
    "objectID": "sessions/week4_lecture.html#but-what-does-it-mean",
    "href": "sessions/week4_lecture.html#but-what-does-it-mean",
    "title": "Linear Algebra",
    "section": "But what does it mean???",
    "text": "But what does it mean???\nEquations are often used in the methods sections of papers to describe the model.\n\n\n\nTaken from: Chiou, Jou, & Yang, (2015). Factors affecting public transportation usage rate: Geographically weighted regression. Transportation Research Part A: Policy and Practice.\n\n\n\nThis is an equation for a geographically weighted regression model."
  },
  {
    "objectID": "sessions/week4_lecture.html#mathematical-models",
    "href": "sessions/week4_lecture.html#mathematical-models",
    "title": "Linear Algebra",
    "section": "Mathematical models",
    "text": "Mathematical models\n\nMathematical models help us to understand the data\nIn a regression setting the model describes a function that maps input to real-valued outputs\nWe can use mathematical models to validate our hypotheses/research questions\n\n\nThinking back to hypotheses from last week - mathematical models help us to evaluate our research question. Lats week we looked at simple statistical tests - but might have a more sophisticated model of what’s happening."
  },
  {
    "objectID": "sessions/week4_lecture.html#machine-learning",
    "href": "sessions/week4_lecture.html#machine-learning",
    "title": "Linear Algebra",
    "section": "Machine learning",
    "text": "Machine learning\nA model which improves after data is taken into account.\n\nMayne of these concepts are also integral to machine learning\nReally just a specific type of mathematical model\nThe learning part is about automatically finding patterns\n\n\nThese ideas are also fundamental for machine learning.\nLots of different definitions of machine learning - but this us a simple one.\nIn later weeks of the course we will look at machine learning concepts."
  },
  {
    "objectID": "sessions/week4_lecture.html#mathematical-notation",
    "href": "sessions/week4_lecture.html#mathematical-notation",
    "title": "Linear Algebra",
    "section": "Mathematical notation",
    "text": "Mathematical notation\nGoing to be using some mathematical notation\n\nas this is what’s used in papers!\n\n\nIt’s just a formal way of writing maths.\n\nProvides a universal way of writing and understanding maths."
  },
  {
    "objectID": "sessions/week4_lecture.html#cheat-sheet",
    "href": "sessions/week4_lecture.html#cheat-sheet",
    "title": "Linear Algebra",
    "section": "Cheat sheet",
    "text": "Cheat sheet\nMathematical notation cheat sheet: https://www.upyesp.org/posts/makrdown-vscode-math-notation/"
  },
  {
    "objectID": "sessions/week4_lecture.html#letters-for-numbers",
    "href": "sessions/week4_lecture.html#letters-for-numbers",
    "title": "Linear Algebra",
    "section": "Letters for numbers",
    "text": "Letters for numbers\nThere are mathematical conventions for how we describe different things.\n\n\\(a, b, c\\) represent constants\n\n\\(x, y, z, \\dots\\) represent variables\n\n\\(f, g, h, \\dots\\) represent functions\n\n\\(i, j, \\dots\\) often used for indices (i.e. counting)\n\n\\(a_i\\) means the \\(i\\)-th element of a sequence\n\n\\(A, B, C\\) represent matrices"
  },
  {
    "objectID": "sessions/week4_lecture.html#numbers-replaced-by-letters",
    "href": "sessions/week4_lecture.html#numbers-replaced-by-letters",
    "title": "Linear Algebra",
    "section": "Numbers replaced by letters",
    "text": "Numbers replaced by letters\n\n\nThe power to represent any number!\n\n\n\n\n\n\nThis is powerful as it allows is to represent abstract concepts - a universal x, rather than a specific number."
  },
  {
    "objectID": "sessions/week4_lecture.html#sums",
    "href": "sessions/week4_lecture.html#sums",
    "title": "Linear Algebra",
    "section": "Sums",
    "text": "Sums\nSummation notation is a compact way to write repeated addition.\n\\[\\begin{align}\n\\sum_{i=1}^n a_i = a_1 + a_2 + a_3 + \\dots + a_n\n\\end{align}\\]\n\nExample:\n\\[\\begin{align}\n\\sum_{i=1}^5 i = 1+2+3+4+5 = 15\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#product",
    "href": "sessions/week4_lecture.html#product",
    "title": "Linear Algebra",
    "section": "Product",
    "text": "Product\nProduct notation is a compact way to write repeated multiplication.\n\\[\\begin{align}\n\\prod_{i=1}^n a_i = a_1 \\cdot a_2 \\cdot a_3 \\cdot \\dots \\cdot a_n\n\\end{align}\\]\n\nExample:\n\\[\\begin{align}\n\\prod_{i=1}^4 i = 1 \\cdot 2 \\cdot 3 \\cdot 4 = 24\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#a-little-bit-of-epsilon",
    "href": "sessions/week4_lecture.html#a-little-bit-of-epsilon",
    "title": "Linear Algebra",
    "section": "a little bit of epsilon",
    "text": "a little bit of epsilon\n\\(\\epsilon\\) is used to mean a small, but arbitrary, number.\n\n\nExample:\n\\[\\begin{align}\ny = 2x + \\epsilon\n\\end{align}\\]\n\n\nThis means \\(y\\) is equal to \\(2\\) times \\(x\\) plus a small value. So if \\(x=3\\), then we would expect \\(y\\) to be close to \\(6\\), but not exactly \\(6\\)."
  },
  {
    "objectID": "sessions/week4_lecture.html#what-is-a-function",
    "href": "sessions/week4_lecture.html#what-is-a-function",
    "title": "Linear Algebra",
    "section": "What is a function?",
    "text": "What is a function?\nA function is a mathematical operation which maps an input value to an output value.\n\nMathematical description of a function\n\\[\\begin{align}\nf(x) = y\n\\end{align}\\]\n\n\nMaps values from a domain \\(X\\) to a range \\(Y\\).\n\\[\\begin{align}\nf(x) = y \\text{ for } x \\in X, y \\in Y\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#domain-and-range",
    "href": "sessions/week4_lecture.html#domain-and-range",
    "title": "Linear Algebra",
    "section": "Domain and range",
    "text": "Domain and range\nDomain - the set of all possible input numbers for the function\nExample:\nIn \\(f(x)=y\\), \\(x\\) is the domain.\n\nRange: the set of all possible output numbers from the function\nExample:\nIn \\(f(x)=y\\), \\(y\\) is the range."
  },
  {
    "objectID": "sessions/week4_lecture.html#number-systems",
    "href": "sessions/week4_lecture.html#number-systems",
    "title": "Linear Algebra",
    "section": "Number systems",
    "text": "Number systems\nIn the applied sciences the domain and range are typically \\(\\mathbb N\\) or \\(\\mathbb Z\\) or \\(\\mathbb R\\)\n\n\n\\(\\mathbb N\\)\n\nNatural numbers\n0,1,2,3,4,5,6…\n\n\\(\\mathbb Z\\)\n\nIntegers\n… -4, -3, -2, -1, 0, 1, 2, 3, 4, …\n\n\\(\\mathbb R\\)\n\nReal numbers"
  },
  {
    "objectID": "sessions/week4_lecture.html#data-represented-algebraically",
    "href": "sessions/week4_lecture.html#data-represented-algebraically",
    "title": "Linear Algebra",
    "section": "Data represented algebraically",
    "text": "Data represented algebraically\nAlgebra is a way of expressing numbers in a generalised or abstract form.\nExample:\n\\[\\begin{align}\nx \\in \\mathbb N\n\\end{align}\\]\n\n\nThis is the data represented algebraically.\nTypically a vector of numbers \\(X^n\\)\n\n\\[\\begin{align}\nX^n = (x_1, x_2, x_3, ... , x_n)\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#example-1",
    "href": "sessions/week4_lecture.html#example-1",
    "title": "Linear Algebra",
    "section": "Example 1",
    "text": "Example 1\nProbability density function of normal distribution\n\\[\\begin{align}\nf(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\end{align}\\]\nwhere \\(x \\in \\mathbb N\\) and \\(f(x) \\in [ 0 , 1 ]\\).\n \n\nNote\n\\([0, 1]\\) is the set of real numbers between \\(0\\) and \\(1\\), inclusive of \\(0\\) and \\(1\\).\n\n\nLast lecture we were thinking about PDFs - these are a function. They map the input value, the ‘x’ to the output range which is a probability between 0 and 1."
  },
  {
    "objectID": "sessions/week4_lecture.html#example-2",
    "href": "sessions/week4_lecture.html#example-2",
    "title": "Linear Algebra",
    "section": "Example 2",
    "text": "Example 2\nThe other function we’ve seen is a linear equation.\n\\[\\begin{align}\nf(x) = ax + b\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#linear-equation",
    "href": "sessions/week4_lecture.html#linear-equation",
    "title": "Linear Algebra",
    "section": "Linear equation",
    "text": "Linear equation\nA linear equation is a linear combination of variables.\nExamples include:\n\\[\\begin{align}\nf(x) = ax + b\n\\end{align}\\]\n\n\n“linea” is the latin word for line or string."
  },
  {
    "objectID": "sessions/week4_lecture.html#straight-lines",
    "href": "sessions/week4_lecture.html#straight-lines",
    "title": "Linear Algebra",
    "section": "Straight lines",
    "text": "Straight lines\nGraphically linear equations are straight lines."
  },
  {
    "objectID": "sessions/week4_lecture.html#linear-equations-1",
    "href": "sessions/week4_lecture.html#linear-equations-1",
    "title": "Linear Algebra",
    "section": "Linear equation(s)",
    "text": "Linear equation(s)\nWe can generalise to multiple equations.\n\nThey are:\n\nA system of multiple linear functions\nWhich can be represented by matrices\nThey can have 0, 1, or many solutions"
  },
  {
    "objectID": "sessions/week4_lecture.html#example-1-1",
    "href": "sessions/week4_lecture.html#example-1-1",
    "title": "Linear Algebra",
    "section": "Example 1",
    "text": "Example 1\n\\[\\begin{align}\nx+y=10\n\\end{align}\\]\n\n\nWhat could \\(x\\) and \\(y\\) be?\nCould have \\(x=y=5\\)\nOr \\(x=2.5\\) and \\(y=7.5\\)\n\n\n\nThere are many solutions!!!\nMany solutions = under-specified\n\nUnder-specified but simple to solve!"
  },
  {
    "objectID": "sessions/week4_lecture.html#example-2-1",
    "href": "sessions/week4_lecture.html#example-2-1",
    "title": "Linear Algebra",
    "section": "Example 2",
    "text": "Example 2\n\\[\\begin{align}\nx+y=10\n\\\\\n2x+y=15\n\\end{align}\\]\n\nIn school might have solved this using substitution.\n\nRearrange the first equation to get \\(y=10-x\\)\nSubstituting in we get \\(2x+(10-x)=15\\)\n\\(x+10=15\\) \\(\\implies\\) \\(x=5\\) \\(\\implies\\) \\(y=5\\)\n\n\n\nThere is exactly one solution!\n\nPerfectly specified and we can solve it without too much difficulty"
  },
  {
    "objectID": "sessions/week4_lecture.html#example-3",
    "href": "sessions/week4_lecture.html#example-3",
    "title": "Linear Algebra",
    "section": "Example 3",
    "text": "Example 3\n\\[\\begin{align}\nx_1+x_2+x_3+x_4=10\n\\\\ x_1+4x_2+x_3+x_4=25\n\\\\ x_1+4x_2+43x_3+x_4=37\n\\\\ x_1+4x_2+7x_3+59x_4=1073\n\\end{align}\\]\n\nVery hard to solve!\n\nAn example (when things get more complicated)"
  },
  {
    "objectID": "sessions/week4_lecture.html#matrix-notation",
    "href": "sessions/week4_lecture.html#matrix-notation",
    "title": "Linear Algebra",
    "section": "Matrix notation",
    "text": "Matrix notation\n\\[\\begin{align}\nx_1+x_2+x_3+x_4=10\n\\\\ x_1+4x_2+x_3+x_4=25\n\\\\ x_1+4x_2+43x_3+x_4=37\n\\\\ x_1+4x_2+7x_3+59x_4=1073\n\\end{align}\\]\n\nCan be written as:\n\\[\\begin{align}\n\\begin{bmatrix}1&1&1&1\\cr1&4&1&1\\cr1&4&43&1\\cr1&4&7&59\\end{bmatrix}\\begin{pmatrix}x_1\\cr x_2\\cr x_3\\cr x_4\\end{pmatrix} = \\begin{pmatrix}10\\cr 25\\cr 37\\cr 1073\\end{pmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#generalised-matrix-form",
    "href": "sessions/week4_lecture.html#generalised-matrix-form",
    "title": "Linear Algebra",
    "section": "Generalised matrix form",
    "text": "Generalised matrix form\nThe generalised matrix form (for a 4x4 matrix is):\n\\[\\begin{align}\n\\begin{bmatrix}a_{1,1} & a_{1,2} & a_{1,3} & a_{1,4}\\cr a_{2,1} & a_{2,2} & a_{2,3} & a_{2,4}\\cr a_{3,1} & a_{3,2} & a_{3,3} & a_{3,4}\\cr a_{4,1} & a_{4,2} & a_{4,3} & a_{4,4}\\end{bmatrix}\\begin{pmatrix}x_1\\cr x_2\\cr x_3\\cr x_4\\end{pmatrix} = \\begin{pmatrix}y_1 \\cr y_2 \\cr y_3 \\cr y_4\\end{pmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#along-the-corridor-down-the-stairs",
    "href": "sessions/week4_lecture.html#along-the-corridor-down-the-stairs",
    "title": "Linear Algebra",
    "section": "Along the corridor, down the stairs",
    "text": "Along the corridor, down the stairs\n\n\nMatrices are indexed by row (\\(m\\)) and by column (\\(n\\))."
  },
  {
    "objectID": "sessions/week4_lecture.html#example",
    "href": "sessions/week4_lecture.html#example",
    "title": "Linear Algebra",
    "section": "Example",
    "text": "Example\n\\(m=2\\), \\(n=2\\) matrix:\n\\[\\begin{align}\n\\begin{bmatrix}1&1\\cr1&4\\end{bmatrix}\n\\end{align}\\]\n\n\\(m=3\\), \\(n=2\\) matrix:\n\\[\\begin{align}\n\\begin{bmatrix}1&1&2\\cr1&4&7\\end{bmatrix}\n\\end{align}\\]\n\n\n\nNote\nWhen \\(m=n\\) we have a square matrix."
  },
  {
    "objectID": "sessions/week4_lecture.html#matrix-addition",
    "href": "sessions/week4_lecture.html#matrix-addition",
    "title": "Linear Algebra",
    "section": "Matrix addition",
    "text": "Matrix addition\nWe denote matrices by capital letters: \\(A\\), \\(B\\), …\n\nMatrix addition is element-wise:\n\\[\\begin{align}\n(A+B)_{ij} = A_{ij} + B_{ij}\n\\end{align}\\]\n\n\nExample:\n\\[\\begin{align}\n\\begin{bmatrix}1&1\\cr1&4\\end{bmatrix} +\n\\begin{bmatrix}1&0\\cr2&6\\end{bmatrix} =\n\\begin{bmatrix}2&1\\cr3&10\\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#matrix-multiplication",
    "href": "sessions/week4_lecture.html#matrix-multiplication",
    "title": "Linear Algebra",
    "section": "Matrix multiplication",
    "text": "Matrix multiplication\nMatrix multiplication is row by column.\n\\[\\begin{align}\n(AB){ij} = \\sum{k} A_{ik} B_{kj}\n\\end{align}\\]\n\nExample:\n\\[\\begin{align}\n\\begin{bmatrix}1 & 2\\cr 3 & 4\\end{bmatrix}\n\\begin{bmatrix}5 & 6\\cr 7 & 8\\end{bmatrix}\n=\n\\begin{bmatrix}\n1\\cdot 5 + 2\\cdot 7 & 1\\cdot 6 + 2\\cdot 8 \\cr\n3\\cdot 5 + 4\\cdot 7 & 3\\cdot 6 + 4\\cdot 8\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n19 & 22 \\cr 43 & 50\n\\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#identity-matrix",
    "href": "sessions/week4_lecture.html#identity-matrix",
    "title": "Linear Algebra",
    "section": "Identity matrix",
    "text": "Identity matrix\nThe identity matrix \\(I\\) acts like the number \\(1\\) in multiplication.\nFor any compatible matrix \\(A\\):\n\\[\\begin{align}\nAI = IA = A\n\\end{align}\\]\n\nExample:\n\\[\\begin{align}\nI = \\begin{bmatrix}\n1 & 0 & 0 \\cr\n0 & 1 & 0 \\cr\n0 & 0 & 1\n\\end{bmatrix}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#determinant-of-a-matrix",
    "href": "sessions/week4_lecture.html#determinant-of-a-matrix",
    "title": "Linear Algebra",
    "section": "Determinant of a matrix",
    "text": "Determinant of a matrix\nThe determinant of a square matrix \\(A\\) is a scalar value that gives information about:\n\nWhether \\(A\\) is invertible\n\nHow \\(A\\) scales space (volume/area)\n\nOrientation (positive or negative)\n\nWe write this as \\(\\det(A)\\) or \\(|A|\\)."
  },
  {
    "objectID": "sessions/week4_lecture.html#determinant-of-a-22-matrix",
    "href": "sessions/week4_lecture.html#determinant-of-a-22-matrix",
    "title": "Linear Algebra",
    "section": "Determinant of a 2×2 matrix",
    "text": "Determinant of a 2×2 matrix\nFor\n\\[\\begin{align}\nA = \\begin{bmatrix}\na & b \\cr\nc & d\n\\end{bmatrix}\n\\end{align}\\]\nthe determinant is:\n\\[\\begin{align}\n\\det(A) = ad - bc\n\\end{align}\\]\n\nExample:"
  },
  {
    "objectID": "sessions/week4_lecture.html#inverse-matrix",
    "href": "sessions/week4_lecture.html#inverse-matrix",
    "title": "Linear Algebra",
    "section": "Inverse matrix",
    "text": "Inverse matrix\nThe inverse of a square matrix \\(A\\) is denoted \\(A^{-1}\\) and satisfies:\n\\[\\begin{align}\nAA^{-1} = A^{-1}A = I\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#inverse-matrix-2x2",
    "href": "sessions/week4_lecture.html#inverse-matrix-2x2",
    "title": "Linear Algebra",
    "section": "Inverse matrix (2x2)",
    "text": "Inverse matrix (2x2)\nFor a \\(2 \\times 2\\) matrix A:\n\\[\\begin{align}\nA = \\begin{bmatrix}\na & b \\cr\nc & d\n\\end{bmatrix}\n\\end{align}\\]\nif \\(\\det(A) \\neq 0\\), then the inverse is:\n\\[\\begin{align}\nA^{-1} = \\frac{1}{\\det(A)}\n\\begin{bmatrix}\nd & -b \\cr\n-c & a\n\\end{bmatrix},\n\\quad \\text{where } \\det(A) = ad - bc\n\\end{align}\\]\n\nIf \\(\\det(A) = 0\\), the matrix has no inverse."
  },
  {
    "objectID": "sessions/week4_lecture.html#system-of-equations",
    "href": "sessions/week4_lecture.html#system-of-equations",
    "title": "Linear Algebra",
    "section": "System of equations",
    "text": "System of equations\nRecall that a system of linear equations can be written compactly as:\n\\[\\begin{align}\nAx = y\n\\end{align}\\]\nwhere: - \\(A\\) is the coefficient matrix - \\(x\\) is the vector of unknowns - \\(y\\) is the vector of constants"
  },
  {
    "objectID": "sessions/week4_lecture.html#solving-the-system",
    "href": "sessions/week4_lecture.html#solving-the-system",
    "title": "Linear Algebra",
    "section": "Solving the system",
    "text": "Solving the system\nIf \\(A\\) is invertible (i.e. \\(\\det(A) \\neq 0\\)), we can solve for \\(x\\):\n\\[\\begin{align}\nAx &= y \\\\\nA^{-1}Ax &= A^{-1}y \\\\\nIx &= A^{-1}y \\\\\nx &= A^{-1}y\n\\end{align}\\]\n\nThus, the solution exists and is unique whenever \\(A\\) has an inverse."
  },
  {
    "objectID": "sessions/week4_lecture.html#so-whats-does-it-mean",
    "href": "sessions/week4_lecture.html#so-whats-does-it-mean",
    "title": "Linear Algebra",
    "section": "So whats does it mean?",
    "text": "So whats does it mean?\n\n\n\nTaken from: Chiou, Jou, & Yang, (2015). Factors affecting public transportation usage rate: Geographically weighted regression. Transportation Research Part A: Policy and Practice."
  },
  {
    "objectID": "sessions/week4_lecture.html#take-another-look",
    "href": "sessions/week4_lecture.html#take-another-look",
    "title": "Linear Algebra",
    "section": "Take another look",
    "text": "Take another look\nLink to the paper…"
  },
  {
    "objectID": "sessions/week4_lecture.html#writing-the-equation",
    "href": "sessions/week4_lecture.html#writing-the-equation",
    "title": "Linear Algebra",
    "section": "Writing the equation",
    "text": "Writing the equation\nEquation 1:\n\\[\\begin{align}\ny_i = \\beta_0(u_i, v_i) + \\sum_{k=1}^p \\beta_{ik}(u_i, v_i)x_{ik} + \\epsilon_i\n\\end{align}\\]\nEquation 2:\n\\[\\begin{align}\n\\hat{\\beta}(i) = [X^TW(i)X]^{-1}X^TW(i)Y\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week4_lecture.html#equation-1",
    "href": "sessions/week4_lecture.html#equation-1",
    "title": "Linear Algebra",
    "section": "Equation 1",
    "text": "Equation 1\n\\[\\begin{align}\ny_i = \\beta_0(u_i, v_i) + \\sum_{k=1}^p \\beta_{ik}(u_i, v_i)x_{ik} + \\epsilon_i\n\\end{align}\\]\nwhere:\n\n\\(y_i\\): the outcome (response) for observation \\(i\\)\n\\(\\beta_0(u_i,v_i)\\): the intercept, which can vary with location \\((u_i,v_i)\\)\n\\(\\sum_{k=1}^p \\beta_{ik}(u_i,v_i) x_{ik}\\): the weighted sum of predictors \\(x_{ik}\\), where each predictor has its own coefficient that may depend on \\((u_i,v_i)\\)\n\\(\\epsilon_i\\): the error term for observation \\(i\\)\n\n\nRead the equation out"
  },
  {
    "objectID": "sessions/week4_lecture.html#translating-equation-1",
    "href": "sessions/week4_lecture.html#translating-equation-1",
    "title": "Linear Algebra",
    "section": "Translating equation 1",
    "text": "Translating equation 1\n\\[\\begin{align}\ny_i = \\beta_0(u_i, v_i) + \\sum_{k=1}^p \\beta_{ik}(u_i, v_i)x_{ik} + \\epsilon_i\n\\end{align}\\]\nThe outcome \\(y_i\\) is explained by an intercept and a weighted combination of predictors, with coefficients that may change depending on the location \\((u_i,v_i)\\), plus some error."
  },
  {
    "objectID": "sessions/week4_lecture.html#equation-2",
    "href": "sessions/week4_lecture.html#equation-2",
    "title": "Linear Algebra",
    "section": "Equation 2",
    "text": "Equation 2\n\\[\\begin{align}\n\\hat{\\beta}(i) = [X^TW(i)X]^{-1}X^TW(i)Y\n$\\hat{\\beta}(i)$: the estimated coefficients at location $i$\n\\end{align}\\]\nwhere:\n\n\\(X\\): the matrix of predictor variables\n\\(Y\\): the vector of observed outcomes\n\\(W(i)\\): a weight matrix that depends on location \\(i\\)\n\\(X^T\\): the transpose of \\(X\\)\n\\([X^TW(i)X]^{-1}\\): the inverse of the weighted cross-product matrix\n\n\nRead the equation out"
  },
  {
    "objectID": "sessions/week4_lecture.html#translating-equation-2",
    "href": "sessions/week4_lecture.html#translating-equation-2",
    "title": "Linear Algebra",
    "section": "Translating equation 2",
    "text": "Translating equation 2\n\\[\\begin{align}\n\\hat{\\beta}(i) = [X^TW(i)X]^{-1}X^TW(i)Y\n$\\hat{\\beta}(i)$: the estimated coefficients at location $i$\n\\end{align}\\]\nThe estimated coefficients \\(\\hat{\\beta}(i)\\) are obtained by solving a weighted least squares problem: take the predictors \\(X\\), weight them with \\(W(i)\\), and solve for the coefficients that best fit \\(Y\\)."
  },
  {
    "objectID": "sessions/week4_lecture.html#covered",
    "href": "sessions/week4_lecture.html#covered",
    "title": "Linear Algebra",
    "section": "Covered",
    "text": "Covered\nWe’ve covered:\n\nMathematical notation\nSums and Products\nFunctions\nMatrices\nAlgebraic representations"
  },
  {
    "objectID": "sessions/week4_lecture.html#key-takeaways",
    "href": "sessions/week4_lecture.html#key-takeaways",
    "title": "Linear Algebra",
    "section": "Key takeaways",
    "text": "Key takeaways\n\nCan use mathematical notation to write equations in a univeral language.\nLinear algebra helps us to solve systems of linear equations.\n\n\nIf in doubt:\n\n\nUse the maths cheat sheet!"
  },
  {
    "objectID": "sessions/week3_practical.html",
    "href": "sessions/week3_practical.html",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "",
    "text": "This week is focussed on defining research hypotheses, and using statistical tests to evaluate them. In particular we will use the Student’s T-test, and the KS distribution test."
  },
  {
    "objectID": "sessions/week3_practical.html#to-add-a-callout-note",
    "href": "sessions/week3_practical.html#to-add-a-callout-note",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nThis practical follows on from practical 2, so if you haven’t done that yet I suggest going back and working through that first!"
  },
  {
    "objectID": "sessions/week3_practical.html#loading-the-data",
    "href": "sessions/week3_practical.html#loading-the-data",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "Loading the data",
    "text": "Loading the data\nWe are going to look at schools perfomance data in England once again.\nThe data is sourced from  and is downloadable here.\nWe have saved a copy of this dataset to the Github repo, in case that the dataset is removed from the website.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as sps\nimport numpy as np \n\n# Read CSV file, handling common missing value entries\nna_vals = [\"\", \"NA\", \"SUPP\", \"NP\", \"NE\", \"SP\", \"SN\", \"SUPPMAT\"]\ndf_ks4 = pd.read_csv(\n    'L2_data/england_ks4final.csv',\n    na_values = na_vals\n)\n\ninfo_cols = ['RECTYPE', 'LEA', 'SCHNAME', 'TOTPUPS', 'TOWN']\nebaccs_cols = ['EBACCAPS', 'EBACCAPS_LO', 'EBACCAPS_MID', 'EBACCAPS_HI']\n\ndf_ks4 = df_ks4[info_cols + ebaccs_cols]\n\ndf_ks4[['TOTPUPS']+ebaccs_cols] = df_ks4[['TOTPUPS']+ebaccs_cols].apply(pd.to_numeric, errors='coerce')\n\ndf_ks4 = df_ks4[df_ks4['RECTYPE'].isin([1, 2])].copy()\n\ndf_ks4.head()\n\n/tmp/ipykernel_12585/485655404.py:8: DtypeWarning: Columns (75,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,144,145,146,147,148,149,150,151,152,177,178,179,180,181,182,183,186,187,188,189,190,191,192,194,195,196,198,199,200,202,203,204,206,207,208,210,211,212,214,215,216,218,219,220,222,223,224,230,233,234,235,236,237,238,239,242,243,244,245,246,247,248,251,252,253,254,255,256,257,266,267,268,269,270,271,272,281,282,283,284,285,286,287,296,297,298,299,300,301,302,311,312,313,314,315,316,317,335,336,337,340,341,342,345,346,347,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_ks4 = pd.read_csv(\n\n\n\n\n\n\n\n\n\nRECTYPE\nLEA\nSCHNAME\nTOTPUPS\nTOWN\nEBACCAPS\nEBACCAPS_LO\nEBACCAPS_MID\nEBACCAPS_HI\n\n\n\n\n0\n1\n201.0\nCity of London School\n1045.0\nLondon\n2.10\nNaN\nNaN\nNaN\n\n\n1\n1\n201.0\nCity of London School for Girls\n739.0\nLondon\n1.51\nNaN\nNaN\nNaN\n\n\n2\n1\n201.0\nDavid Game College\n365.0\nNaN\n0.56\nNaN\nNaN\nNaN\n\n\n4\n1\n202.0\nAcland Burghley School\n1163.0\nLondon\n4.62\n1.91\n3.81\n6.87\n\n\n5\n1\n202.0\nThe Camden School for Girls\n1047.0\nLondon\n6.25\nNaN\n5.40\n7.21\n\n\n\n\n\n\n\nLooking at the metadata (which you can see in ‘L2_data/ks4_meta.xlsx’) we can see the full meaning of each column header:\n\n‘RECTYPE’ = Record type (1=mainstream school; 2=special school; 4=local authority; 5=National (all schools); 7=National (maintained schools))\n‘LEA’ = Local authority\n‘SCHNAME’ = School name\n‘TOTPUPS’ = Number of pupils on roll (all ages)\n‘TOWN’ = School town\n‘EBACCAPS’ = Average EBacc APS score per pupil\n‘EBACCAPS_LO’ = Average EBacc APS score per pupil with low prior attainment\n‘EBACCAPS_MID’ = Average EBacc APS score per pupil with middle prior attainment\n‘EBACCAPS_HI’ = Average EBacc APS score per pupil with high prior attainment"
  },
  {
    "objectID": "sessions/week3_practical.html#research-question",
    "href": "sessions/week3_practical.html#research-question",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "Research question",
    "text": "Research question\nThe department for education is worried about regional inequality in school grades. With this in mind they’ve come up with a research question they’d like to address.\nResearch question: Is average pupil attainment on the EBacc significantly different in London compared to the rest of England?\nTo do this we’re going to use the mean comparison test to compare the schools in London to those outside of London."
  },
  {
    "objectID": "sessions/week3_practical.html#preparing-the-data",
    "href": "sessions/week3_practical.html#preparing-the-data",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "Preparing the data",
    "text": "Preparing the data\n\nSplitting the groups\n\ndf_London = df_ks4[df_ks4['TOWN'] == 'London']\ndf_London = df_London[df_London['EBACCAPS'].notna()]\n\ndf_notLondon = df_ks4[df_ks4['TOWN'] != 'London']\ndf_notLondon = df_notLondon[df_notLondon['EBACCAPS'].notna()]\n\nAnd lets look at the summary statistics for each group.\n\ndf_London['EBACCAPS'].describe()\n\ncount    385.000000\nmean       3.788260\nstd        1.851894\nmin        0.000000\n25%        3.020000\n50%        4.290000\n75%        4.970000\nmax        8.700000\nName: EBACCAPS, dtype: float64\n\n\n\ndf_notLondon['EBACCAPS'].describe()\n\ncount    4246.000000\nmean        3.395921\nstd         1.659090\nmin         0.000000\n25%         2.820000\n50%         3.670000\n75%         4.380000\nmax         8.560000\nName: EBACCAPS, dtype: float64\n\n\nSo from looking at their summary statistics the two groups are different sizes. The two groups also have different means - but we want to test if these means are statistically significantly different."
  },
  {
    "objectID": "sessions/week3_practical.html#the-hypothesis-test",
    "href": "sessions/week3_practical.html#the-hypothesis-test",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "The hypothesis test",
    "text": "The hypothesis test\nWe’re now going to work through the steps of the hypothesis test according to the five steps discussed in the lecture:\n\nDefine the null and alternative hypothesis\nSet you significance level\nIdentify the evidence\nCalculate the p-value\nCompare p-value with hypothesis level\n\n\nStep 1\nWhat is the null and alternative hypothesis?\n\nQuestionAnswer\n\n\nH_0 = '??'\nH_1 = '??'\n\nprint(f'The null hypothesis is {H_0}')\nprint(f'The alternative hypothesis is {H_1}')\n\n\nH_0 = 'Mean EBacc score in London = Mean EBacc score outside London'\nH_1 = 'Mean EBacc score in London &gt; Mean EBacc score outside London OR Mean EBacc score in London &lt; Mean EBacc score outside London'\n\nprint(f'The null hypothesis is {H_0}')\nprint(f'The alternative hypothesis is {H_1}')\nThe null hypothesis is Mean EBacc score in London = Mean EBacc score outside London\nThe alternative hypothesis is Mean EBacc score in London &gt; Mean EBacc score outside London OR Mean EBacc score in London &lt; Mean EBacc score outside London\n\n\n\n\n\nStep 2\n\n# Set the level of statistical significance \n\nalpha = 0.05\n\n\n\nStep 3\nWe already have the evidence - it’s our datasets df_London['EBACCAPS'] and df_notLondon['EBACCAPS'].\n\n\nStep 4\nWe can use a built in function from scipy.stats called ttest_ind to do step 4 for us. You can read more about this function here.\nFirst we need to check whether we can assume that the samples are drawn from populations with the same standard deviation or not. (Provided neither standard deviation is double the other, this should be ok).\n\nLondon_std = df_London['EBACCAPS'].mean()\nnotLondon_std = df_notLondon['EBACCAPS'].mean()\n\n# Calculate the ratio of standard deviations \nstd_ratio = London_std/notLondon_std\n\nprint(\"std ratio =\", std_ratio)\n\nif std_ratio &gt; 0.5 and std_ratio &lt; 2:\n    print(\"Can assume equal population standard deviations.\")\n    equal_stds = True\nelse:\n    print(\"Cannot assume equal population standard deviations.\")\n    equal_stds = False\n\nstd ratio = 1.115532395766086\nCan assume equal population standard deviations.\n\n\nThere are two outputs from the function scipy.stats.ttest_ind: the test statistic and the p value.\n\ntest_stat, p_value = sps.ttest_ind(df_London['EBACCAPS'], df_notLondon['EBACCAPS'], equal_var = equal_stds)\n\nprint(\"test statistic = \", test_stat)\nprint(\"p-value =\", p_value)\n\ntest statistic =  4.398340904538903\np-value = 1.1153058452679495e-05\n\n\n\n\nStep 5\nFor the final step we compare the p-value to the significance value in order to reach a decision.\n\nQuestionAnswer\n\n\nif p_value ?? ?? :\n    print(f\"Reject the null hypothesis ({H_0}). Accept the alternative hypothesis ({H_1}).\")\n    print(\"Conclude that samples are drawn from populations with different means.\")\nelif p_value ?? ?? :\n    print(f\"No significant evidence to reject the null hypothesis ({H_0}).\")\n    print(\"Assume samples are drawn from populations with the same mean.\")\n\n\nif p_value &lt; alpha:\n    print(f\"Reject the null hypothesis ({H_0}). Accept the alternative hypothesis ({H_1}).\")\n    print(\"Conclude that samples are drawn from populations with different means.\")\nelif p_value &gt;= alpha:\n    print(f\"No significant evidence to reject the null hypothesis ({H_0}).\")\n    print(\"Assume samples are drawn from populations with the same mean.\")\nReject the null hypothesis (Mean EBacc score in London = Mean EBacc score outside London). Accept the alternative hypothesis (Mean EBacc score in London &gt; Mean EBacc score outside London OR Mean EBacc score in London &lt; Mean EBacc score outside London).\nConclude that samples are drawn from populations with different means.\n\n\n\nHence we can conclude that the evidence supports there is a statistically significant differnece between the mean student attainment on the EBacc in London, versus outside of London."
  },
  {
    "objectID": "sessions/week3_practical.html#a-more-complicated-research-question",
    "href": "sessions/week3_practical.html#a-more-complicated-research-question",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "A more complicated research question",
    "text": "A more complicated research question\nNow I’d also like to know: Are the distribution of EBacc scores in London drawn from a normal distribution?"
  },
  {
    "objectID": "sessions/week3_practical.html#youre-done",
    "href": "sessions/week3_practical.html#youre-done",
    "title": "Practical 3: Establishing and testing the hypothesis",
    "section": "You’re Done!",
    "text": "You’re Done!\nWell done you’ve completed this weeks practical on establishing and evaluating hypothesis questions. If you are still working on it, take your time. And if you have any questions just ask!"
  },
  {
    "objectID": "sessions/week3.html",
    "href": "sessions/week3.html",
    "title": "Week 3",
    "section": "",
    "text": "This week will introduce hypothesis testing, and key statistical tests for evaluating hypotheses.",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#introduction",
    "href": "sessions/week3.html#introduction",
    "title": "Week 3",
    "section": "",
    "text": "This week will introduce hypothesis testing, and key statistical tests for evaluating hypotheses.",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#learning-objectives",
    "href": "sessions/week3.html#learning-objectives",
    "title": "Week 3",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nEstablish a hypothesis for a given research project.\nDefine the Type I and Type II errors.\nEvaluate a hypothesis using appropriate statistical tests.",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#lecture",
    "href": "sessions/week3.html#lecture",
    "title": "Week 3",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#quiz",
    "href": "sessions/week3.html#quiz",
    "title": "Week 3",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#practical",
    "href": "sessions/week3.html#practical",
    "title": "Week 3",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week3.html#further-resources",
    "href": "sessions/week3.html#further-resources",
    "title": "Week 3",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 1: Basics",
      "3. Hypothesis Testing"
    ]
  },
  {
    "objectID": "sessions/week2_lecture.html#overview-of-lecture-1",
    "href": "sessions/week2_lecture.html#overview-of-lecture-1",
    "title": "Exploratory Data Analysis 2",
    "section": "Overview of lecture 1",
    "text": "Overview of lecture 1\n\nDifferent data types\nKey data metrics\n\nthe middle and the spread\n\nVisualising the data\nData outliers\n\n\n4 data types: nominal, ordinal, interval, ratio Numerical vs categorical\nKey data metrics - the middle: mean, median, mode and the spread: variance and standard deviation\ndifferent types of data outliers: caused by measurement error, or irregular pattern or influential outliers"
  },
  {
    "objectID": "sessions/week2_lecture.html#first-things-first",
    "href": "sessions/week2_lecture.html#first-things-first",
    "title": "Exploratory Data Analysis 2",
    "section": "First things first",
    "text": "First things first\n\n\n\n\n\n\n\nExploratory data analysis is the first step of any data science project.\n\n\nlink to scientific process and how we test and then iterate over ideas and concepts. Something we will talk about more next lecture."
  },
  {
    "objectID": "sessions/week2_lecture.html#introducing-statistical-concepts",
    "href": "sessions/week2_lecture.html#introducing-statistical-concepts",
    "title": "Exploratory Data Analysis 2",
    "section": "Introducing statistical concepts",
    "text": "Introducing statistical concepts\n\nThis lecture is focussed on statistical concepts\nData science is about using ideas from statistics to describe large datasets\nHere looking to describe numerical data\nFocus on probability distributions\n\n\nIn large datasets its not practical to describe every data point - instead interested in the overall pattern. Moreover maybe that general pattern is more interetsing"
  },
  {
    "objectID": "sessions/week2_lecture.html#learning-objectives",
    "href": "sessions/week2_lecture.html#learning-objectives",
    "title": "Exploratory Data Analysis 2",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should be able to:\n\nDescribe the characteristic features of common probability distributions.\nCalculate exponentials and logarithms.\nEvaluate whether a dataset is representative."
  },
  {
    "objectID": "sessions/week2_lecture.html#what-is-the-likelihood-of-events-occuring",
    "href": "sessions/week2_lecture.html#what-is-the-likelihood-of-events-occuring",
    "title": "Exploratory Data Analysis 2",
    "section": "What is the likelihood of events occuring?",
    "text": "What is the likelihood of events occuring?\nQuestion\nWhat is the probability of someone at UCL being over 190cm?\n\nHow can we try to answer this?\n\n\n\nWe could try and find someone on campus who is over 190cm.\n\n\n\nBetter to try and understand the distribution of heights.\n\nThis week thinking about the distribution of data. How do we understand the spread of height data, how to we calculate important features of this data, how can we describe this data using mathematical equations?\nNext week, thinking about formulating and answering the research question."
  },
  {
    "objectID": "sessions/week2_lecture.html#the-dream-vs-reality",
    "href": "sessions/week2_lecture.html#the-dream-vs-reality",
    "title": "Exploratory Data Analysis 2",
    "section": "The dream vs reality",
    "text": "The dream vs reality\nIdeally, we would like all the relevant data.\n\n… in reality we normally only have some.\n\n\n\n\nIt would be great if I knew the height of everyone at UCL, but unrealistic to collect – however maybe I could collect all students in this lecture theatre."
  },
  {
    "objectID": "sessions/week2_lecture.html#approximating",
    "href": "sessions/week2_lecture.html#approximating",
    "title": "Exploratory Data Analysis 2",
    "section": "Approximating",
    "text": "Approximating\nHence, we sample a subset of the data.\n\nWe need to choose our sample carefully. We want what happens in the sample to approximate what happens in the whole population.\n\n\nIn practise\n\ndifferent sampling approaches\n\nrandom sampling\nsystematic sampling\n\n\n\nI might assign everyone a number and then choose 100 random numbers and measure them. Or I might choose a specific subset, for exampel just everyone in this lecture theatre."
  },
  {
    "objectID": "sessions/week2_lecture.html#bias",
    "href": "sessions/week2_lecture.html#bias",
    "title": "Exploratory Data Analysis 2",
    "section": "Bias",
    "text": "Bias\nIt’s important to understand if your dataset is unrepresentative or biased.\n\n\n\n\nBias is the idea that there is an unrepresentative pattern in your data."
  },
  {
    "objectID": "sessions/week2_lecture.html#cognitive-bias",
    "href": "sessions/week2_lecture.html#cognitive-bias",
    "title": "Exploratory Data Analysis 2",
    "section": "Cognitive bias",
    "text": "Cognitive bias\nSystematic patterns in how we think about, and perceive, the world.\n\n\nWe all have cognitive biases.\nThese can impact our research:\n\ndata collection\ndata selection\ndata processing\nmodelling choices\n\n\n \n\n\n\n\n\nExample of cognitive bias - confirmation bias, whereby I favour information that agrees with my existing beliefs. I’m writing a report on the spatial impact of a new railway line. Suppose I hate the idea of a new railway line, and then I see some data, fact a: 60% of residents living near the railline don’t want it due to noise. fact b: 75% of residents in the UK do want the railway line. i might only include fact a in my report as it confirms my existing beliefs."
  },
  {
    "objectID": "sessions/week2_lecture.html#why-is-this-important",
    "href": "sessions/week2_lecture.html#why-is-this-important",
    "title": "Exploratory Data Analysis 2",
    "section": "Why is this important?",
    "text": "Why is this important?\nIf we’re not careful we can propagate bias to the research, and hence results.\n\nThis can lead to incorrect conclusions.\n\nAs scientists we should try and present an accurate and fair balance of information. If we’re more aware of our biases it can be easier to try and actively avoid them."
  },
  {
    "objectID": "sessions/week2_lecture.html#types-of-bias",
    "href": "sessions/week2_lecture.html#types-of-bias",
    "title": "Exploratory Data Analysis 2",
    "section": "Types of bias",
    "text": "Types of bias\n\nResearch bias Cognitive bias is a specific type of research bias.\nDataset bias Particularly important when thinking about analysing large datasets, as there could be non-obvious patterns reflecting biases.\n\nTypes of dataset bias include: - Historical bias - Selection bias\n\nAlready talked about the idea of cognitive bias. There are lots and lots of different types of biases - going to talk a little about different ways they can bias the dataset.\nDataset bias has become a more prevalent topic of concern on the era of large AI models. These models are really good at learnign patterns which aren’t obvious to the human eye - but the pattern might reflect a bias. For example generative AI models learn that scientists are white men, even though if I asked you you’d tell me anyone can be a scientist."
  },
  {
    "objectID": "sessions/week2_lecture.html#historical-bias",
    "href": "sessions/week2_lecture.html#historical-bias",
    "title": "Exploratory Data Analysis 2",
    "section": "Historical bias",
    "text": "Historical bias\nReflects existing, real world, inequalities\nExamples:\n\nPolice profiling\n\nAutomated tools to detect ‘criminals’.\nTrained on datasets which reflect current racist practises.\n\nHungry judges\n\nTools to help sentencing of ‘criminals’.\nPatterns in the dataset — judges are less lenient before lunch.\n\n\n\nPolice profiling models - meant to make easy to spot criminals - but use exisitng crime data - which reflect racist prejudices in society - and the model learns to pick out people of certain ethnic backgrounds.\nTools also used to help the sentnecing of criminals in courts of law - observe the hungry judges effect, where they sentnece differently based on how hungry they are - tend to be harsher just before lunch and more lenient after lunch."
  },
  {
    "objectID": "sessions/week2_lecture.html#selection-bias",
    "href": "sessions/week2_lecture.html#selection-bias",
    "title": "Exploratory Data Analysis 2",
    "section": "Selection bias",
    "text": "Selection bias\nWhen the sample chosen doesn’t represent the whole population of interest\nExamples:\n\nSelf selection Roy Model\n\nUnderlying characteristics of people who self select into certain groups.\n\nWEIRD people\n\nCommonly sampled in behavioural sciences.\nReflects a very small proportion of global population.\n\n\n\nRoy model - example from economics - basically there’s not a random selection of people in a specific job - thye have chosen that job based on underlying unobserved characterisitcs. For example suppose I’m interested in wages of workers in different occupations - but they have self-selected into that occupation based on their unique skill set - so it’s a biased representation.\nWEIRD = western, educated, industrialised, rich, democratic"
  },
  {
    "objectID": "sessions/week2_lecture.html#can-data-ever-be-truly-representative",
    "href": "sessions/week2_lecture.html#can-data-ever-be-truly-representative",
    "title": "Exploratory Data Analysis 2",
    "section": "Can data ever be truly representative?",
    "text": "Can data ever be truly representative?\nProbably not.\n\nEven when we think we have really good data, someone has made the choice to collect this data. Why that data over other data? Does that data reflect their underlying cognitive biases? For example the choice to collect information of peoples opnion about a new trainline might be driven by a political goal of understanding public support for a new government infrastructure project.\nNot necessarilly a bad thing, but important to keep in mind. And if the bias is noticeable then it should be acknowledged and reported.\n\n\nFailing that… .. we can acknowledge our biases!\n\n\n\nImage credit: [xkcd](https://xkcd.com/2494/)"
  },
  {
    "objectID": "sessions/week2_lecture.html#what-to-declare",
    "href": "sessions/week2_lecture.html#what-to-declare",
    "title": "Exploratory Data Analysis 2",
    "section": "What to declare",
    "text": "What to declare\nDescriptive statistics refers to the most basic statistical information about the dataset.\n\n\nSample size (n)\nMean, median, mode\nStandard deviation\nRange"
  },
  {
    "objectID": "sessions/week2_lecture.html#example-1",
    "href": "sessions/week2_lecture.html#example-1",
    "title": "Exploratory Data Analysis 2",
    "section": "Example 1",
    "text": "Example 1\n\n\nLet’s look at a dataset of students height.\n\nEasy to print the summary statistics in Python, using pandas:\n\nimport pandas as pd \n\nheight_df = pd.read_csv(\"L2_data/heights.csv\")\nheight_df.describe().round(2)\n\n\n\n\n\n\n\n\n\n\n\nHeight_cm\n\n\n\n\ncount\n1000.00\n\n\nmean\n161.19\n\n\nstd\n9.79\n\n\nmin\n128.59\n\n\n25%\n154.52\n\n\n50%\n161.25\n\n\n75%\n167.48\n\n\nmax\n199.53"
  },
  {
    "objectID": "sessions/week2_lecture.html#example-2",
    "href": "sessions/week2_lecture.html#example-2",
    "title": "Exploratory Data Analysis 2",
    "section": "Example 2",
    "text": "Example 2\nSometimes we need more information.\n\nimport pandas as pd \n\n# read data\ndf_4datasets = pd.read_csv(\"L2_data/anscombe_quartet.csv\")\n# print descriptive statistics\ndf_4datasets.groupby(\"dataset\").describe()\n\n\n\n\n\n\n\n\nx\ny\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\ndataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1\n11.0\n9.0\n3.316625\n4.0\n6.5\n9.0\n11.5\n14.0\n11.0\n7.500909\n2.031568\n4.26\n6.315\n7.58\n8.57\n10.84\n\n\n2\n11.0\n9.0\n3.316625\n4.0\n6.5\n9.0\n11.5\n14.0\n11.0\n7.500909\n2.031657\n3.10\n6.695\n8.14\n8.95\n9.26\n\n\n3\n11.0\n9.0\n3.316625\n4.0\n6.5\n9.0\n11.5\n14.0\n11.0\n7.500000\n2.030424\n5.39\n6.250\n7.11\n7.98\n12.74\n\n\n4\n11.0\n9.0\n3.316625\n8.0\n8.0\n8.0\n8.0\n19.0\n11.0\n7.500909\n2.030579\n5.25\n6.170\n7.04\n8.19\n12.50\n\n\n\n\n\n\n\n\nall 4 datasets have very similar descriptive statistics of both the x, and y variables."
  },
  {
    "objectID": "sessions/week2_lecture.html#same-same-but-different",
    "href": "sessions/week2_lecture.html#same-same-but-different",
    "title": "Exploratory Data Analysis 2",
    "section": "Same same but different",
    "text": "Same same but different\n\n\n\n\nThese all have mean x = 9, variance x = 11. mean y = 7.5, variance y =4.1.\nBut we can see from the diagrams that the distribution of the data is very different, some is linear, some is elliptic etc… So we need more advanced ways of describing the data."
  },
  {
    "objectID": "sessions/week2_lecture.html#everywhere-you-look",
    "href": "sessions/week2_lecture.html#everywhere-you-look",
    "title": "Exploratory Data Analysis 2",
    "section": "Everywhere you look",
    "text": "Everywhere you look\n\n\n\n\n\nHuman height\nPetal size (specifically length of iris petals)\nblood pressure\nbirth weight of babies\nmeasurement errors in science experiments"
  },
  {
    "objectID": "sessions/week2_lecture.html#youve-seen-it-all-before",
    "href": "sessions/week2_lecture.html#youve-seen-it-all-before",
    "title": "Exploratory Data Analysis 2",
    "section": "You’ve seen it all before",
    "text": "You’ve seen it all before\n\nSymmetrical\nSingle peak\nSmooth tails on both sides"
  },
  {
    "objectID": "sessions/week2_lecture.html#naturally-occurring",
    "href": "sessions/week2_lecture.html#naturally-occurring",
    "title": "Exploratory Data Analysis 2",
    "section": "Naturally occurring",
    "text": "Naturally occurring"
  },
  {
    "objectID": "sessions/week2_lecture.html#naturally-occurring-1",
    "href": "sessions/week2_lecture.html#naturally-occurring-1",
    "title": "Exploratory Data Analysis 2",
    "section": "Naturally occurring",
    "text": "Naturally occurring"
  },
  {
    "objectID": "sessions/week2_lecture.html#uniquely-described-by-two-variables",
    "href": "sessions/week2_lecture.html#uniquely-described-by-two-variables",
    "title": "Exploratory Data Analysis 2",
    "section": "Uniquely described by two variables…",
    "text": "Uniquely described by two variables…"
  },
  {
    "objectID": "sessions/week2_lecture.html#and-a-probability-distribution-function",
    "href": "sessions/week2_lecture.html#and-a-probability-distribution-function",
    "title": "Exploratory Data Analysis 2",
    "section": "…and a probability distribution function",
    "text": "…and a probability distribution function\n\n\n\nThe probability density function (PDF) describes the likelihood of different outcomes for a continuous random variable"
  },
  {
    "objectID": "sessions/week2_lecture.html#key-features",
    "href": "sessions/week2_lecture.html#key-features",
    "title": "Exploratory Data Analysis 2",
    "section": "Key features",
    "text": "Key features\n\nData is continuous\n\nit is something you measure not something you count\n\nData is equally likely to be larger or smaller than average\n\nsymmetric\n\nCharacteristic size, all data points are close to the mean\n\nsingle peak\n\nThere is less data further away from the mean\n\nsmooth tails on both sides"
  },
  {
    "objectID": "sessions/week2_lecture.html#sampling-distributions",
    "href": "sessions/week2_lecture.html#sampling-distributions",
    "title": "Exploratory Data Analysis 2",
    "section": "Sampling distributions",
    "text": "Sampling distributions\nThe distribution of the random variable when derived from a random sample of size \\(n\\)\n\nIn the case of the normal distribution - standard deviation becomes:\n\\[\\begin{align}\n\\frac{\\sigma}{\\sqrt{n}}\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#calculating-probabilities",
    "href": "sessions/week2_lecture.html#calculating-probabilities",
    "title": "Exploratory Data Analysis 2",
    "section": "Calculating probabilities",
    "text": "Calculating probabilities\nCan use the PDF to evaluate the probability at a specific point.\n\\[\\begin{align}\nx \\sim N(0,1)\n\\end{align}\\]\n\n\\[\\begin{align}\np(x) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}\n\\end{align}\\]\n\n\n\\[\\begin{align}\np(x=0.5) = \\frac{1}{\\sqrt{2 \\pi \\times 1^2}} e^{-\\frac{(0.5-0)^2}{(2\\times 1)^2}}\n\\\\\n= \\frac{1}{\\sqrt{2 \\pi}} e^{-\\frac{0.25}{4}} = 0.3747\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#not-everything-is-normal",
    "href": "sessions/week2_lecture.html#not-everything-is-normal",
    "title": "Exploratory Data Analysis 2",
    "section": "Not everything is normal",
    "text": "Not everything is normal\nMany real world datasets are approximately normally distributed.\n\nBut not all — might not have a characteristic size, or not continuous, or not symmetric."
  },
  {
    "objectID": "sessions/week2_lecture.html#continuous-vs.-discrete",
    "href": "sessions/week2_lecture.html#continuous-vs.-discrete",
    "title": "Exploratory Data Analysis 2",
    "section": "Continuous vs. Discrete",
    "text": "Continuous vs. Discrete\nContinuous data Measurable data which can take any value within a given range.\nexample: height\nDiscrete data Measurable data which can take seperate, countable values.\nexample: shoe size\n\nSuppose I have someone who is x cm tall, and someone who is y cm tall, I can find someone in between whose x.5cm tall.\nBut shoe sizes are discrete (not the length of your foot)."
  },
  {
    "objectID": "sessions/week2_lecture.html#back-to-the-probability-function",
    "href": "sessions/week2_lecture.html#back-to-the-probability-function",
    "title": "Exploratory Data Analysis 2",
    "section": "Back to the probability function",
    "text": "Back to the probability function\n\\[\\begin{align}\np(x)\n\\end{align}\\]\nHaving a function for the distribution allows us to evaluate the probability of events, and hence evaluate hypotheses.\n\nFor discrete distributions we have the probability mass function.\n\n\nSampling distributions\nAs for the normal distribution, in the general case we should be aware of the sampling distribution."
  },
  {
    "objectID": "sessions/week2_lecture.html#coin-toss",
    "href": "sessions/week2_lecture.html#coin-toss",
    "title": "Exploratory Data Analysis 2",
    "section": "Coin toss",
    "text": "Coin toss\n\n\n\nI flip a coin 10 times\nHow often can I expect to get at least 7 heads?\n\n\n \n\n\n\n\n\nDiscrete outcomes Describes the frequency of successes in a test with 2 outcomes. Coin flip is the classic example - have exactly two outcomes, either heads or tails."
  },
  {
    "objectID": "sessions/week2_lecture.html#probability-mass-function",
    "href": "sessions/week2_lecture.html#probability-mass-function",
    "title": "Exploratory Data Analysis 2",
    "section": "Probability mass function",
    "text": "Probability mass function\n\\[\\begin{align}\nP(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}\n\\end{align}\\]\nWhere \\(n\\) is the number of trials, and \\(p\\) is the probability of success for each trial.\n\nThe probability mass function (PMF) describes the likelihood of different outcomes for a discrete random variable\n\nNote the combination here."
  },
  {
    "objectID": "sessions/week2_lecture.html#plotting-the-distribution",
    "href": "sessions/week2_lecture.html#plotting-the-distribution",
    "title": "Exploratory Data Analysis 2",
    "section": "Plotting the distribution",
    "text": "Plotting the distribution"
  },
  {
    "objectID": "sessions/week2_lecture.html#example",
    "href": "sessions/week2_lecture.html#example",
    "title": "Exploratory Data Analysis 2",
    "section": "Example",
    "text": "Example\n\nI flip a coin 10 times\n\n\\(n=10\\), \\(p=0.5\\)\n\nHow often can I expect to get at least 7 heads?\n\n\\(k \\geq 7\\)\n\n\n\nEvaluating the PMF, we get:\n\\[\\begin{align}\nP(X \\geq 7) &= P(X=7) + P(X=8) + P(X=9) + P(X=10)\n\\\\\n&= 0.1719\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#death-by-horse-kicks",
    "href": "sessions/week2_lecture.html#death-by-horse-kicks",
    "title": "Exploratory Data Analysis 2",
    "section": "Death by horse kicks",
    "text": "Death by horse kicks\n\n\n\nIt’s 1894.\nYou’re the statistician Ladislaus Bortkiewicz.\nAnd you’re wondering,\nHow many soldiers in the Prussian army have been killed by horse kicks?"
  },
  {
    "objectID": "sessions/week2_lecture.html#measuring-rare-events",
    "href": "sessions/week2_lecture.html#measuring-rare-events",
    "title": "Exploratory Data Analysis 2",
    "section": "Measuring rare events",
    "text": "Measuring rare events\n\nImagine a situation where certain rare events (like arrival of mail) can occur in an independent fashion.\nThe Poisson distribution estimates how many such events are expected within a time interval\nFixed interval (e.g. one minute)\nFixed rate of events (\\(\\lambda\\)) (e.g. 4 cars per minute, \\(\\lambda=4\\))\nPoisson distribution gives the probability of \\(k\\) events.\n\n\nTypically used to measure rare events like mail arriving or death by horse kicks."
  },
  {
    "objectID": "sessions/week2_lecture.html#probability-mass-function-1",
    "href": "sessions/week2_lecture.html#probability-mass-function-1",
    "title": "Exploratory Data Analysis 2",
    "section": "Probability mass function",
    "text": "Probability mass function\n\\[\\begin{align}\nP(X = k) = \\frac{\\lambda^k e^{- \\lambda}}{k!}\n\\end{align}\\]\nWhere \\(\\lambda\\) is the expected number of events in a given interval."
  },
  {
    "objectID": "sessions/week2_lecture.html#plotting-the-distribution-1",
    "href": "sessions/week2_lecture.html#plotting-the-distribution-1",
    "title": "Exploratory Data Analysis 2",
    "section": "Plotting the distribution",
    "text": "Plotting the distribution"
  },
  {
    "objectID": "sessions/week2_lecture.html#example-3",
    "href": "sessions/week2_lecture.html#example-3",
    "title": "Exploratory Data Analysis 2",
    "section": "Example",
    "text": "Example\n\nBetween 1883 and 1893 there were an average of 2 deaths from horse kicks a year.\n\n\\(\\lambda=2\\)\n\nWhat’s the probability of seeing 10 deaths from horse kicks in 1894?\n\n\n\\[\\begin{align}\nP(X = 10) = \\frac{2^10 e^{-2}}{10!}\n\\\\ = 0.000038\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#exponentials",
    "href": "sessions/week2_lecture.html#exponentials",
    "title": "Exploratory Data Analysis 2",
    "section": "Exponentials",
    "text": "Exponentials\nIf the Poisson measures the probability of x events within a time period, then the Exponential measures how long we are likely to wait between events.\n\nThe greatest shortcoming of the human race is our inability to understand the exponential function – Albert Bartlett (physicist)\n\nHe’s a bit dramatic"
  },
  {
    "objectID": "sessions/week2_lecture.html#a-game-of-chess",
    "href": "sessions/week2_lecture.html#a-game-of-chess",
    "title": "Exploratory Data Analysis 2",
    "section": "A game of chess…",
    "text": "A game of chess…\n\n\n\n\nYou’ve invented chess.\nThe emperor is really grateful - and asks what gift you would like in thanks.\nYou ask for grains of rice.\n\nSpecifically, rice to fill the chessboard, such that the number of grains double on each square.\n\n\n\n\n\nImage credit: https://simple.wikipedia.org/wiki/Chaturanga\n\n\n\n\nFamous story, of the man who invented chess. Emperor was so grateful, he said what do you want in return The man asked for rice, such that on each square of the chess board, the number of grains of rice doubled. The Emperor thought this was a really small ask for such a great invention. He asked if he didn’t want a better gift. But the man insisted that what he wanted was rice.\nImage is of Chatarunga - which is the earliest known form of chess dating to 6th century AD northern India."
  },
  {
    "objectID": "sessions/week2_lecture.html#and-rice",
    "href": "sessions/week2_lecture.html#and-rice",
    "title": "Exploratory Data Analysis 2",
    "section": "…and rice",
    "text": "…and rice\n\n\n\n\n\n\n. . .\n10^18\n. . .\nWhich is more than the global production of rice.\n\n\nA bowl of rice is around 4,000 grains."
  },
  {
    "objectID": "sessions/week2_lecture.html#what-does-this-look-like-on-a-graph",
    "href": "sessions/week2_lecture.html#what-does-this-look-like-on-a-graph",
    "title": "Exploratory Data Analysis 2",
    "section": "What does this look like on a graph?",
    "text": "What does this look like on a graph?"
  },
  {
    "objectID": "sessions/week2_lecture.html#generally-we-have",
    "href": "sessions/week2_lecture.html#generally-we-have",
    "title": "Exploratory Data Analysis 2",
    "section": "Generally we have",
    "text": "Generally we have"
  },
  {
    "objectID": "sessions/week2_lecture.html#the-exponential-function",
    "href": "sessions/week2_lecture.html#the-exponential-function",
    "title": "Exploratory Data Analysis 2",
    "section": "The exponential function",
    "text": "The exponential function\nThe (natural) exponential function is:\n\\[\\begin{align}\ny=e^x\n\\end{align}\\]\n\\(e\\) here is eulers number - a mathematical constant.\n\\[\\begin{align}\ne \\approx 2.718...\n\\end{align}\\]\n\nIts a mathematical constant similar to pi - it’s just a fixed number which we have a name for. Like pi comes from geometry (circles etc), e comes from the limit of the equation of compound interest."
  },
  {
    "objectID": "sessions/week2_lecture.html#when-i-can-feed-my-town",
    "href": "sessions/week2_lecture.html#when-i-can-feed-my-town",
    "title": "Exploratory Data Analysis 2",
    "section": "When I can feed my town?",
    "text": "When I can feed my town?\nAllows us to answer questions like:\n\n“how many grains of rice at t=10?”\n“when will I have enough rice to feed my entire town?”\n\n\nThis is easier said than done – the best way is to invert the equation."
  },
  {
    "objectID": "sessions/week2_lecture.html#inverse-operations",
    "href": "sessions/week2_lecture.html#inverse-operations",
    "title": "Exploratory Data Analysis 2",
    "section": "Inverse operations",
    "text": "Inverse operations\nThe mathematical operation that reverses.\nSubtract is the inverse of adding.\n\\[\\begin{align}\n2 + x=5 \\implies 5-2=x\n\\end{align}\\]\nDivide is the inverse of multiplying.\n\\[\\begin{align}\n2 \\times x =6 \\implies 6 \\div 2=x\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#logarithms",
    "href": "sessions/week2_lecture.html#logarithms",
    "title": "Exploratory Data Analysis 2",
    "section": "Logarithms",
    "text": "Logarithms\nTaking the logarithm is the inverse of taking the exponential.\n\n\\[\\begin{align}\n2^3 = 8 \\implies \\log_2(8) =3\n\\end{align}\\]\n\n\nMore generally:\n\\[\\begin{align}\na^x = b \\implies \\log_a(b) =x\n\\end{align}\\]\n\n\nFor the natural logarithm:\n\\[\\begin{align}\ne^x = b \\implies \\log_e(b) =ln(b) = x\n\\end{align}\\]\n\n\nMultiply and divide are inverse operations of one another (they reverse the process).\nRead the equation as log of 8 base 2 equals 3."
  },
  {
    "objectID": "sessions/week2_lecture.html#natural-logarithm",
    "href": "sessions/week2_lecture.html#natural-logarithm",
    "title": "Exploratory Data Analysis 2",
    "section": "Natural logarithm",
    "text": "Natural logarithm"
  },
  {
    "objectID": "sessions/week2_lecture.html#log-rules",
    "href": "sessions/week2_lecture.html#log-rules",
    "title": "Exploratory Data Analysis 2",
    "section": "Log rules",
    "text": "Log rules\nThere are some general rules for how we apply logarithms:\n\\[\\begin{align}\nlog_a(b \\times c) &= log_a(b) + log_a(c)\n\\\\ log_a(\\frac{b}{c}) &= log_a(b)-loc_b(c)\n\\\\ log_a(b^c) &= c \\times log_a(b)\n\\\\ log_a(1)&=0\n\\\\ log_a(a)&=1\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week2_lecture.html#transforming-data",
    "href": "sessions/week2_lecture.html#transforming-data",
    "title": "Exploratory Data Analysis 2",
    "section": "Transforming data",
    "text": "Transforming data\nSome of the most important rules:\n\\[\\begin{align}\nlog_a(a^x) = x\n\\\\ ln(e^x) = x\n\\end{align}\\]\n\nWhen we have exponential data we can take the logarithm of it - and hence simplify it.\n\nWe will return to the idea of taking the log of data in future weeks - especially in the context of regression analyses."
  },
  {
    "objectID": "sessions/week1_practical.html",
    "href": "sessions/week1_practical.html",
    "title": "Practical 1: describing and representing data",
    "section": "",
    "text": "This week is focussed on ensuring that you’re able to access the teaching materials and to run Jupyter notebooks locally, as well as describing a dataset in Python."
  },
  {
    "objectID": "sessions/week1_practical.html#learning-outcomes",
    "href": "sessions/week1_practical.html#learning-outcomes",
    "title": "Practical 1: describing and representing data",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nYou have familiarised yourself with how to access the lecture notes and Python notebook of this module.\nYou have familiarised yourself with running the Python notebooks locally.\nYou have familiarised yourself with describing a dataset in Python."
  },
  {
    "objectID": "sessions/week1_practical.html#set-up-the-tools",
    "href": "sessions/week1_practical.html#set-up-the-tools",
    "title": "Practical 1: describing and representing data",
    "section": "Set up the tools",
    "text": "Set up the tools\nPlease follow the Setup page of CASA0013 to install and configure the computing platform, and this page to get started on using the container & JupyterLab."
  },
  {
    "objectID": "sessions/week1_practical.html#download-the-notebook",
    "href": "sessions/week1_practical.html#download-the-notebook",
    "title": "Practical 1: describing and representing data",
    "section": "Download the Notebook",
    "text": "Download the Notebook\nSo for this week, visit the Week 1 of QM page, you’ll see that there is a ‘preview’ link and a a ‘download’ link. If you click the preview link you will be taken to the GitHub page for the notebook where it has been ‘rendered’ as a web page, which is not editable. To make the notebook useable on your computer, you need to download the IPYNB file.\nSo now:\n\nClick on the Download link.\nThe file should download automatically, but if you see a page of raw code, select File then Save Page As....\nMake sure you know where to find the file (e.g. Downloads or Desktop).\nMove the file to your Git repository folder (e.g. ~/Documents/CASA/QM/)\nCheck to see if your browser has added .txt to the file name:\n\nIf no, then you can move to adding the file.\nIf yes, then you can either fix the name in the Finder/Windows Explore, or you can do this in the Terminal using mv &lt;name_of_practical&gt;.ipynb.txt &lt;name_of_practical&gt;.ipynb (you can even do this in JupyterLab’s terminal if it’s already running)."
  },
  {
    "objectID": "sessions/week1_practical.html#running-notebooks-on-jupyterlab",
    "href": "sessions/week1_practical.html#running-notebooks-on-jupyterlab",
    "title": "Practical 1: describing and representing data",
    "section": "Running notebooks on JupyterLab",
    "text": "Running notebooks on JupyterLab\nI am assuming that most of you are already running JupyterLab via Podman using the command.\nIf you are a bit confused with container, JupyterLab, terminal, or Git, please feel free to ask any questions."
  },
  {
    "objectID": "sessions/week1_practical.html#loading-data",
    "href": "sessions/week1_practical.html#loading-data",
    "title": "Practical 1: describing and representing data",
    "section": "Loading data",
    "text": "Loading data\nWe are going to describe the population of local authorities in the UK.\nThe data is sourced from Office for National Statistics and is donwloadable here.\nWe have saved a copy of this dataset to the Github repo, in case that the dataset is removed from the website.\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2  \n\n\nYou might wonder why skipping the first 5 rows and setting thousands=‘,’. I knew about this after opening this csv file in a text editor and lots of trial-and-errors.\n\n\nThen, we check the first few rows of this dataset using df_pop.head()."
  },
  {
    "objectID": "sessions/week1_practical.html#describing-the-dataframe",
    "href": "sessions/week1_practical.html#describing-the-dataframe",
    "title": "Practical 1: describing and representing data",
    "section": "Describing the dataframe",
    "text": "Describing the dataframe\n\nWhich columns are included?\n\nlist(df_pop.columns)\n\n['Area code',\n 'Area name',\n 'Area type',\n 'Population 2011',\n 'Population 2021',\n 'Percentage change']\n\n\nIt is a pain to deal with whitespaces in a column, so good practice is to replace the whitespaces (eg tabs, multiple spaces) within column names with underscore.\n\ndf_pop.columns = df_pop.columns.str.replace(r'\\s+', '_', regex=True)\nprint(list(df_pop.columns)) # check again\n\n['Area_code', 'Area_name', 'Area_type', 'Population_2011', 'Population_2021', 'Percentage_change']\n\n\n\n\nHow many rows & cols are included?\n\nrows, cols = df_pop.shape\nprint(f\"Rows: {rows}, Columns: {cols}\")\n\nRows: 369, Columns: 6\n\n\n\n\nGeography matters\nThis dataset contains multiple geographies of UK and different geographies are incomparable. We can check the Area_type column:\n\nprint(df_pop.Area_type.value_counts())\n\nArea_type\nLocal Authority    355\nRegion               9\nCountry              2\nNational             1\nName: count, dtype: int64\n\n\nSo there are 355 records of Local Authority， 9 records of Region, 2 of Country, and 1 of ‘National’. For an introduction to these terms, see this article on ONS.\nWe will focus on the local authorities, so we apply a filter:\n\ndf_pop_la = df_pop[df_pop['Area_type'] == 'Local Authority']\n\n\n\nOverview of the columns\nThere are two pandas functions that give overview of a dataframe. - info(): shows column data types, non‑null counts, and memory usage. - describe(): shows summary statistics for numeric data (count, mean, std, min, quartiles, max) - describe(include='all'): for both numeric data and non‑numeric data (count, unique, top value, frequency).\n\nprint(df_pop_la.info())\nprint(df_pop_la.describe())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 355 entries, 12 to 366\nData columns (total 6 columns):\n #   Column             Non-Null Count  Dtype  \n---  ------             --------------  -----  \n 0   Area_code          355 non-null    object \n 1   Area_name          355 non-null    object \n 2   Area_type          355 non-null    object \n 3   Population_2011    355 non-null    float64\n 4   Population_2021    355 non-null    float64\n 5   Percentage_change  355 non-null    float64\ndtypes: float64(3), object(3)\nmemory usage: 19.4+ KB\nNone\n       Population_2011  Population_2021  Percentage_change\ncount     3.550000e+02     3.550000e+02         355.000000\nmean      2.132867e+05     2.268876e+05           6.070423\nstd       2.099628e+05     2.245442e+05           4.608338\nmin       2.203000e+03     2.054000e+03          -9.600000\n25%       1.000530e+05     1.055705e+05           2.950000\n50%       1.382650e+05     1.477760e+05           5.800000\n75%       2.487865e+05     2.628895e+05           9.000000\nmax       1.463740e+06     1.576069e+06          22.100000"
  },
  {
    "objectID": "sessions/week1_practical.html#describing-census-2021-population",
    "href": "sessions/week1_practical.html#describing-census-2021-population",
    "title": "Practical 1: describing and representing data",
    "section": "Describing census 2021 population",
    "text": "Describing census 2021 population\nNow, we focus on describing the local authority population from census 2021. The first question is, what data type is this variable - nominal, ordinal, interval, or ratio？\n\n\n\n\n\n\nNote\n\n\n\nThe data type of a variable is different from how it’s stored in a computer. For example, the Area_type variable can be encoded for convenience as 0 (“national”), 1 (“country”), and 2 (“local authority”). Although these are stored as numbers, Area_type is not truly numeric data — it’s an nominal variable.\n\n\nDoes it make sense to say ‘the population of LA AAA is twice of LA BBB’? Yes. So, this variable is of ratio type.\n\nmax and min\nWhat is the maximum population size in census 2021?\nprint(\"Max population: \", df_pop_la['Population_2021'].max(skipna=True))\nWhich LAs have the maximum population size? The code below is a bit complicated.\n\nprint(\"{} have the maximum population of {}\".format(\n    \", \".join(df_pop_la.loc[df_pop_la['Population_2021'] == df_pop_la['Population_2021'].max(skipna=True), 'Area_name']), \n    df_pop_la['Population_2021'].max(skipna=True))\n    )\n\nKent have the maximum population of 1576069.0\n\n\nWhat it does:\n\nFinds the max population while ignoring NaNs. It is always safe to use skipna=True, even though there is no NA values.\nSelects all rows with that population.\nJoins their Area_name values into a comma-separated string.\n\nTwo new Python functions here:\n\nformat(): Inserts variables into a string by replacing {} placeholders in order with provided arguments.\njoin(): Combines the elements of an iterable into one string using the given separator before .join().\n\nWhich LAs have the minimum population?\n\nprint(\"{} have the minimum population of {}\".format(\n    \", \".join(df_pop_la.loc[df_pop_la['Population_2021'] == df_pop_la['Population_2021'].min(skipna=True), 'Area_name']), \n    df_pop_la['Population_2021'].min(skipna=True))\n    )\n\nIsles of Scilly have the minimum population of 2054.0\n\n\n\n\nStandard deviation\nThe result from df_pop_la.describe() indicates that the standard deviation of Population_2021 is 2.245442e+05.\nAnother way to calculate this standard deviation and to reformat it is:\n\nstd_dev = df_pop_la['Population_2021'].std()\n# plain notation\nprint(\"The standard deviation of Population_2021 is: {}\".format(std_dev)) \n# scientific notation\nprint(\"Using scientific notation: {:.3e}\".format(std_dev)) \n# thousands separator notation + 2 decimal places\nprint(\"Using thousands separator notation: {:,.2f}\".format(std_dev))\n\nThe standard deviation of Population_2021 is: 224544.20636612535\nUsing scientific notation: 2.245e+05\nUsing thousands separator notation: 224,544.21\n\n\nThere are several ways to represent numbers, and which one you choose depends on the situation.\nEqually important is to ensure the numbers are meaningful, or to use proper significant figures. For example, reporting a population’s standard deviation with 10 decimal places does not make sense.\n\n\nNull value and outliers?\nAre there Null values or outliers in this variable? From results of info(), there are no NA values.\nTo detect outliers, we will implement the Tukey Fences method using pandas function, as pandas does not provide a built-in function for this method.\n\n# Calculate Q1, Q3, and IQR\nQ1 = df_pop_la['Population_2021'].quantile(0.25)\nQ3 = df_pop_la['Population_2021'].quantile(0.75)\nIQR = Q3 - Q1\n\n# Tukey's fences\nlower_bound = Q1 - 1.5 * IQR\nupper_bound = Q3 + 1.5 * IQR\n\n# Detect outliers\noutliers = df_pop_la[\n    (df_pop_la['Population_2021'] &lt; lower_bound) |\n    (df_pop_la['Population_2021'] &gt; upper_bound)\n]\n\nprint(\"Lower bound:\", lower_bound)\nprint(\"Upper bound:\", upper_bound)\nprint(\"How many outliers?\", outliers.shape[0])\nprint(\"Outliers:\\n\", outliers)\n\nLower bound: -130408.0\nUpper bound: 498868.0\nHow many outliers? 33\nOutliers:\n      Area_code        Area_name        Area_type  Population_2011  \\\n56   E06000047    County Durham  Local Authority         513242.0   \n60   E06000052         Cornwall  Local Authority         532273.0   \n62   E06000054        Wiltshire  Local Authority         470981.0   \n68   E06000060  Buckinghamshire  Local Authority         505283.0   \n254  E08000003       Manchester  Local Authority         503127.0   \n270  E08000019        Sheffield  Local Authority         552698.0   \n275  E08000025       Birmingham  Local Authority        1073045.0   \n282  E08000032         Bradford  Local Authority         522452.0   \n285  E08000035            Leeds  Local Authority         751485.0   \n321  E10000003   Cambridgeshire  Local Authority         621210.0   \n322  E10000006          Cumbria  Local Authority         499858.0   \n323  E10000007       Derbyshire  Local Authority         769686.0   \n324  E10000008            Devon  Local Authority         746399.0   \n325  E10000011      East Sussex  Local Authority         526671.0   \n326  E10000012            Essex  Local Authority        1393587.0   \n327  E10000013  Gloucestershire  Local Authority         596984.0   \n328  E10000014        Hampshire  Local Authority        1317788.0   \n329  E10000015    Hertfordshire  Local Authority        1116062.0   \n330  E10000016             Kent  Local Authority        1463740.0   \n331  E10000017       Lancashire  Local Authority        1171339.0   \n332  E10000018   Leicestershire  Local Authority         650489.0   \n333  E10000019     Lincolnshire  Local Authority         713653.0   \n334  E10000020          Norfolk  Local Authority         857888.0   \n335  E10000023  North Yorkshire  Local Authority         598376.0   \n336  E10000024  Nottinghamshire  Local Authority         785802.0   \n337  E10000025      Oxfordshire  Local Authority         653798.0   \n338  E10000027         Somerset  Local Authority         529972.0   \n339  E10000028    Staffordshire  Local Authority         848489.0   \n340  E10000029          Suffolk  Local Authority         728163.0   \n341  E10000030           Surrey  Local Authority        1132390.0   \n342  E10000031     Warwickshire  Local Authority         545474.0   \n343  E10000032      West Sussex  Local Authority         806892.0   \n344  E10000034   Worcestershire  Local Authority         566169.0   \n\n     Population_2021  Percentage_change  \n56          522068.0                1.7  \n60          570305.0                7.1  \n62          510330.0                8.4  \n68          553078.0                9.5  \n254         551938.0                9.7  \n270         556521.0                0.7  \n275        1144919.0                6.7  \n282         546412.0                4.6  \n285         811953.0                8.0  \n321         678849.0                9.3  \n322         499846.0                0.0  \n323         794636.0                3.2  \n324         811640.0                8.7  \n325         545847.0                3.6  \n326        1503521.0                7.9  \n327         645076.0                8.1  \n328        1400899.0                6.3  \n329        1198798.0                7.4  \n330        1576069.0                7.7  \n331        1235354.0                5.5  \n332         712366.0                9.5  \n333         768364.0                7.7  \n334         916120.0                6.8  \n335         615491.0                2.9  \n336         824822.0                5.0  \n337         725291.0               10.9  \n338         571547.0                7.8  \n339         876104.0                3.3  \n340         760688.0                4.5  \n341        1203108.0                6.2  \n342         596773.0                9.4  \n343         882676.0                9.4  \n344         603676.0                6.6  \n\n\nThere are 33 outliers in this dataset. Think about the three types of outliers that we discussed. Which type do these 33 outliers beloong to?\n\nError Outlier\nIrregular Pattern Outlier\nInfluential Outlier\n\n\n\nBoxplot\nTo create a boxplot of this variable:\n\nimport matplotlib.pyplot as plt\n\n# Create boxplot\ndf_pop_la['Population_2021'].plot(kind='box', title='LA Population 2021 Boxplot')\n\nplt.ylabel('Population')\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.show()\n\n\n\n\n\n\n\n\nWhat do you observe from this boxplot? There are lots of values above the"
  },
  {
    "objectID": "sessions/week1_practical.html#exploring-percentage_change",
    "href": "sessions/week1_practical.html#exploring-percentage_change",
    "title": "Practical 1: describing and representing data",
    "section": "Exploring Percentage_change",
    "text": "Exploring Percentage_change\nNow, we turn to explore the variable Percentage_change, which represents the relative change from the 2011 census to 2021 census.\nTry completing the code below on your own. Practice makes perfect!\n\nWhich LAs experienced the largest population percentage change? To what extent?\n\nQuestionAnswer\n\n\nprint(\"{} have the largest population percentage change of {}%\".format(\n    \", \".join(df_pop_la.loc[??['??'] == ??['??'].max(skipna=True), 'Area_name']), \n    df_pop_la['Population_2021'].??(skipna=True))\n    )\n\n\nprint(\"{} have the largest population percentage change of {}%\".format(\n    \", \".join(df_pop_la.loc[df_pop_la['Percentage_change'] == df_pop_la['Percentage_change'].max(skipna=True), 'Area_name']), \n    df_pop_la['Percentage_change'].max(skipna=True))\n    )\nTower Hamlets have the largest population percentage change of 22.1%\n\n\n\n\n\nWhich LAs experienced the smallest population percentage change? To what extent?\n\nQuestionAnswer\n\n\nprint(\"{} have the smallest population percentage change of {}%\".format(\n    \", \".??(df_pop_la.loc[df_pop_la[??] == ??['Percentage_change'].??(skipna=True), 'Area_name']), \n    df_pop_la['Percentage_change'].??(skipna=True))\n    )\n\n\nprint(\"{} have the smallest population percentage change of {}%\".format(\n    \", \".join(df_pop_la.loc[df_pop_la['Percentage_change'] == df_pop_la['Percentage_change'].min(skipna=True), 'Area_name']), \n    df_pop_la['Percentage_change'].min(skipna=True))\n    )\nKensington and Chelsea have the smallest population percentage change of -9.6%\n\n\n\n\n\nMaking a boxplot of Percentage_change\n\nQuestionAnswer\n\n\nimport matplotlib.pyplot as plt\n\n# Create boxplot\ndf_pop_la[??].plot(kind=??, title='LA Population Percentage Change Boxplot')\n\nplt.??('Percentage change')\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.show()\n\n\nimport matplotlib.pyplot as plt\n\n# Create boxplot\ndf_pop_la['Percentage_change'].plot(kind='box', title='LA Population Percentage Change Boxplot')\n\nplt.ylabel('Percentage change')\nplt.grid(axis='y', linestyle='--', alpha=0.6)\nplt.show()"
  },
  {
    "objectID": "sessions/week1_practical.html#youre-done",
    "href": "sessions/week1_practical.html#youre-done",
    "title": "Practical 1: describing and representing data",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/week10.html",
    "href": "sessions/week10.html",
    "title": "Week 10",
    "section": "",
    "text": "This week will introduce how to group similar data points together to discover patterns and structures within a dataset.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#introduction",
    "href": "sessions/week10.html#introduction",
    "title": "Week 10",
    "section": "",
    "text": "This week will introduce how to group similar data points together to discover patterns and structures within a dataset.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#learning-objectives",
    "href": "sessions/week10.html#learning-objectives",
    "title": "Week 10",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nUnderstand the principle and purpose of clustering analysis.\nUnderstand K-Means and apply K-Means to various datasets.\nInterpret the results of clustering analysis.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#lecture",
    "href": "sessions/week10.html#lecture",
    "title": "Week 10",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#quiz",
    "href": "sessions/week10.html#quiz",
    "title": "Week 10",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#practical",
    "href": "sessions/week10.html#practical",
    "title": "Week 10",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/week10.html#further-resources",
    "href": "sessions/week10.html#further-resources",
    "title": "Week 10",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 3: Dimension Reduction & Clustering",
      "10. Clustering"
    ]
  },
  {
    "objectID": "sessions/index.html",
    "href": "sessions/index.html",
    "title": "Overview",
    "section": "",
    "text": "Coding alone is not enough.\nUnderstanding models aids in correct tool selection and bug handling.\nGoogle/ChatGPT can make mistakes; detecting them is crucial.\nMathematics understanding is not always required.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#why-study-a-quantitative-methods-course",
    "href": "sessions/index.html#why-study-a-quantitative-methods-course",
    "title": "Overview",
    "section": "",
    "text": "Coding alone is not enough.\nUnderstanding models aids in correct tool selection and bug handling.\nGoogle/ChatGPT can make mistakes; detecting them is crucial.\nMathematics understanding is not always required.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#objectives",
    "href": "sessions/index.html#objectives",
    "title": "Overview",
    "section": "Objectives",
    "text": "Objectives\n\nUnderstand the structure and focus of the module.\nDevelop a method for tackling quantitative problems.\nFormulate a research question and structure quantitative writing.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#course-objectives",
    "href": "sessions/index.html#course-objectives",
    "title": "Overview",
    "section": "Course Objectives",
    "text": "Course Objectives\n\nUnderstand a broad range of quantitative techniques.\nApply these skills in research.\nFormulate a coherent quantitative argument.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#prerequisites",
    "href": "sessions/index.html#prerequisites",
    "title": "Overview",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nNo prerequisite of university-level maths/statistics.\nNo prerequisite of programming.\nPython is required for practicals and assessments.\nThis module doesn’t teach programming, so CASA0013 is strongly recommneded if you don’t know Python before.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#course-structure",
    "href": "sessions/index.html#course-structure",
    "title": "Overview",
    "section": "Course Structure",
    "text": "Course Structure\n\nLectures: Wednesdays 9:00–10:30; G13 Torrington Place (1-19).\nTutorials: Wednesdays 10:30–12:30; G13 Torrington Place (1-19).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#platforms",
    "href": "sessions/index.html#platforms",
    "title": "Overview",
    "section": "Platforms",
    "text": "Platforms\n\nEmail for important notices and private questions.\nGithub & website for lecture notes and notebooks.\nMoodle for lectures recording and assessments.\nSlack for public questions.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#weekly-schedule",
    "href": "sessions/index.html#weekly-schedule",
    "title": "Overview",
    "section": "Weekly Schedule",
    "text": "Weekly Schedule\n\n\n\nSession\nTopic\nLecturer\n\n\n\n\n1\nIntroduction to data\nHuanfa\n\n\n2\nProbability and distribution\nBea\n\n\n3\nHypothesis testing\nBea\n\n\n4\nIntroduction to linear algebra\nBea\n\n\n5\nCorrelation and regression\nHuanfa\n\n\n6\nMultiple regression\nAdam\n\n\n7\nGeneralised linear model\nAdam\n\n\n8\nMultilevel regression\nAdam\n\n\n9\nDimensionality reduction\nHuanfa\n\n\n10\nClustering Analysis\nHuanfa",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#assessment-1",
    "href": "sessions/index.html#assessment-1",
    "title": "Overview",
    "section": "Assessment",
    "text": "Assessment\n\nWritten Investigation (summative): 100%\nWeekly quiz (formative)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#ucl-assessment-policy",
    "href": "sessions/index.html#ucl-assessment-policy",
    "title": "Overview",
    "section": "UCL Assessment Policy",
    "text": "UCL Assessment Policy\n\nAll submissions via Moodle, not emails.\nLate penalties: Up to 2 working days (-10 points); up to 7 working days (capped at 50); over 7 working days (scores 0).\nDAP or Extenuating circumstances: to submit on Portico.\nRespect word count limits\nAvoid plagiarism and unverified references",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#moodle-feedback",
    "href": "sessions/index.html#moodle-feedback",
    "title": "Overview",
    "section": "Moodle Feedback",
    "text": "Moodle Feedback\nPlease provide anonymous feedback on Moodle",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "sessions/index.html#github-feedback",
    "href": "sessions/index.html#github-feedback",
    "title": "Overview",
    "section": "Github Feedback",
    "text": "Github Feedback\nYou can also give feedback on Github issues.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "help.html",
    "href": "help.html",
    "title": "Getting Help",
    "section": "",
    "text": "We all need help from time to time, and while we will always do our best to support you because we know that this module is hard for students who are new to quantitative modules or statistics, the best way to ‘get help’ will also always be taking steps to ‘help yourself’ first."
  },
  {
    "objectID": "help.html#how-to-help-yourself",
    "href": "help.html#how-to-help-yourself",
    "title": "Getting Help",
    "section": "How to Help Yourself",
    "text": "How to Help Yourself\nHere are at least six things that you can do to ‘help yourself’:\n\nMake use of practical sessions–we can’t help you if we don’t know that you’re struggling. Please talk to the lecturer or TAs during the pratical sessions.\nUse the dedicated #casa0007_qm channel on Slack –this provides a much richer experience than the Moodle Forum and should be your primary means of requesting help outside of scheduled teaching hours.\nDo the readings–regardless of whether we ask you questions in class about them (or not), the readings are designed to support the module’s learning outcomes, so if you are struggling with a concept or an idea then please look to the week’s readings! You should also review the full bibliography while developing your thinking for the final project.\nUse Google or Stack Overflow–as you become a better programmer you’ll start to understand how to frame your question in ways that produce the right answer right away, but whether you’re a beginner or an expert Stack Overflow is your friend.\nSign up for online classes–there are lots of plausible online classes on LinkedIn course or Coursera. Please check the reviews before you take an online module."
  },
  {
    "objectID": "assessments/index.html",
    "href": "assessments/index.html",
    "title": "CASA0007 Assessment",
    "section": "",
    "text": "This Assessment is worth 100% of the grade for this course.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "assessments/index.html#assessment-aims",
    "href": "assessments/index.html#assessment-aims",
    "title": "CASA0007 Assessment",
    "section": "Assessment Aims",
    "text": "Assessment Aims\nThis assessment is designed to test your understanding of the quantitative methods introduced in this course, but also, crucially, your ability to really understand how, if used correctly and applied to appropriate data, these methods can help you tell a powerful story and be the underpinning evidence-base for a relevant local, national or international issue.\nUsing quantitative methods to contribute to public debates is vital if students, academics and universities are to demonstrate our value to the wider world. We don’t want you to just apply a method and regurgitate unintelligible coefficients. Quantitative methods can only have real value if they are used to support wider debates in ways that everyone should be able to understand.\nWe are not testing your coding abilities – you may use either of the main coding languages taught this term (R or Python). We are not testing your ability to write a standard piece of academic writing. But we are testing your ability to use quantitative methods appropriately and with a clear connection between the data, methods and outputs, to help others understand a particular issue through a data lens.\n\nPart 1 - Article\nYour task is to write a short 800-1000-word piece of ‘public-facing scholarly writing’ in the style of an article that that could appear in The Conversation or the Financial Times in their data section. This piece could relate to a local, national or international topic which could be either serious or frivolous but must employ appropriate quantitative methods learned in this course to derive novel insights from a particular dataset (or range of datasets) associated with a particular topic of your choosing. Data analysis and the use of quantitative methods should be central to your piece, but outputs must be appropriate for a general (non-academic) audience with your piece illuminated by appropriate visual outputs – maps, graphs or other data visualisations. Your piece should contain a range of graphical or tabular elements.\n\n\nPart 2 - Technical Appendix\nYour 800-1000-word article should be accompanied by a max 1000-word technical appendix detailing the analysis you have carried out behind the scenes to allow you to make the observations you have in your article. Here you might want to include additional exploratory visualisations, tabular outputs, interpretations of those outputs, equations etc. and you could also include any observations about the dataset or the validity / statistical significance of any models you employ. The purpose of the appendix is to reassure anyone who wants to delve deeper, that the observations you made in your main article are valid and reliable and your interpretations valid.\n\n\nTopic\nYour topic can be anything you like broadly related to human, urban or social issues, as long as you can find some suitable data to analyse. For inspiration on relevant topics, you might want to review some of the articles that John Burn-Murdoch has written for the Financial Times in recent years - https://www.ft.com/john-burn-murdoch (you can log-in via your UCL credentials) or some of the pieces in the Conversation - https://theconversation.com/.\nIf you are struggling for inspiration, you are welcome to explore an educational topic using DfE schools data used in class, but you are encouraged to be creative in your data choices (as you are being partially marked on your originality), and you should not repeat analyses carried out on variables in any of the practical sessions. The only topic we will not permit in this assessment is anything related to AirBnB as this is the focus of CASA0013.\n\n\nArticle Content\nYou will note that most of John Burn-Murdoch’s articles generally contain the sorts of analyses we would describe as exploratory. While your article should contain basic exploratory analysis in the form of visualisations, you should also use an appropriate method from the second half of the course (lectures 5-10) related to either more sophisticated exploratory analysis like multivariate statistical analysis (e.g. dimensionality reduction or cluster analysis) or some explanatory / predictive methods such as ANOVA, linear regression or some of the generalised linear models also introduced.\n\n\nStyle of Briefing\nYou should write in plain English and avoid the use of jargon or technical language. For tips on how to write in this style, The Conversation has produced a guide: https://socsci.web.ox.ac.uk/files/conversation-writing-public-why-and-how\n\n\nTypes of Data Permissible and Sources\nAnything you like, but you should choose carefully so that you are able to demonstrate the appropriate skills. There are many potential sources of data – these could be linked from FT or Conversation articles, or you could try sites like:\nhttps://data.gov/\nhttps://www.data.gov.uk/\nhttps://opendata.nhsbsa.net/\nhttps://tfl.gov.uk/info-for/open-data-users/  \nhttps://data.europa.eu/data/datasets?locale=en\nhttps://data.worldbank.org/\nhttps://data.london.gov.uk/\nYou can probably find many more!\n\n\nReferencing\nWe will not expect standard academic referencing in this piece, however, this doesn’t mean that you shouldn’t include references – you should. In this style of public facing scholarly writing, it is common to use hyperlinks and footnotes and you should make use of these to support your narrative.\n\n\nFormat of the Piece\nExamples – Here is just one example of the kind of article you might produce (minus the technical appendix), but read widely around the data journalism sites linked from publications like the Financial Times, New York Times, Guardian.\nhttps://theconversation.com/constituency-level-data-reveals-which-parties-are-most-threatened-by-reform-264422\n\n\nDeadline and Handing In\nThe Deadline for the assessment is Tuesday, 13 January 2026 @ 10:00.\nYour report and technical appendix should be uploaded to Moodle as a single PDF document.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "assessments/index.html#mark-scheme",
    "href": "assessments/index.html#mark-scheme",
    "title": "CASA0007 Assessment",
    "section": "Mark Scheme",
    "text": "Mark Scheme\nThis is how we will mark your work - take note of them\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion\n80-100%\n70-79% (A)\n60-69% (B)\n50-59% (C)\n40-49% (D)\n1-39% (E)\n\n\n\n\nExploratory Analysis (25%)\nOutstanding selection of exploratory statistics and/or sophisticated data visualisations which illuminate the underlying data, revealing distributions / trends / relationships and associations in the data with absolute clarity. Graphics are labelled such that readers are in no doubt about what is being shown. Data may have been transformed, normalised or standardised in some way to reveal otherwise hidden patterns and justified impeccably.\nExcellent selection of exploratory statistics and/or sophisticated data visualisations which illuminate the underlying data, revealing distributions / trends / relationships and associations in the data. Graphics are labelled such that readers are in no doubt about what is being shown. Data may have been transformed, normalised or standardised in some way to reveal otherwise hidden patterns and justified.\nGood selection of exploratory statistics and/or data visualisations which illuminate the underlying data, revealing distributions / trends / relationships and associations. Graphics are labelled such that readers are able to interpret the plots with ease.\nAdequate selection of exploratory statistics and/or data visualisations which illuminate some of the underlying data, revealing some distributions / trends / relationships and associations. Graphics are labelled, but may lack clarity. Data may not be transformed, normalised or standardised in a way to reveal patterns.\nInadequate selection of statistics or visualisations. Graphics are poorly labelled or unclear, and do not illuminate the underlying data. Data transformations are incorrect or missing.\nNegligible use of statistics or visualisations. Any visualisations are irrelevant, inaccurate, or inaccessible. The analysis shows no grasp of the underlying data.\n\n\nUse of multivariate statistical analysis or explanatory / predictive methods (25%)\nExceptional selection of data / variables entirely appropriate for the chosen article topic. Masterful understanding of the nuances related to the careful pruning and selection of appropriate variables. Outstanding understanding of the methods employed and their interaction with the data to hand with masterful understanding of outputs produced\nExcellent selection of data / variables entirely appropriate for the chosen article topic. Highly competent understanding of the nuances related to the careful pruning and selection of appropriate variables. Highly competent understanding of the methods employed and their interaction with the data to hand.\nGood selection of data / variables appropriate for the chosen article topic. Competent understanding of the methods employed and their interaction with the data.\nAdequate selection of data / variables for the chosen article topic. Basic understanding of the methods employed and their interaction with the data. May get some of the nuances in the outputs, but may also ignore some key features in the data\nInadequate selection of data / variables for the chosen article topic. Little to no understanding of the methods employed or how they interact with the data.\nNegligible or irrelevant selection of data / variables. No grasp of the methods or their application to the data.\n\n\nOriginality, article narrative and communication (25%)\nHighly original topic selection, or of exceptional relevance to a contemporary debate in the society, the media or politics at a local, national or international level with broad interest. Article narrative shows flare or originality which draws the reader in and reveals something entirely new. Writing style is highly accessible - clear, concise and creative and the reader is left without query or misunderstanding.\nExcellent topic selection, of high relevance to a contemporary debate. The narrative is engaging and written with excellent clarity, flowing well from one section to the next. The work is of a very high standard. Writing style clear and concise with few wasted words.\nGood topic selection, of relevance to a contemporary debate. The narrative is clear and well-structured. The work shows some evidence of originality. The narrative is good and the message emerging from the analysis is conveyed well.\nAdequate topic selection, but may lack relevance or wider interest. The narrative is satisfactory but may lack clarity or logical flow  ideas appearing slightly disorganised. The reader can understand the piece but may have to work hard to derive meaning from it.\nInadequate topic selection  perhaps dated or totally irrelevant to the degree programme (i.e. not even a human topic). The narrative is lacking in clarity and is difficult to follow. Deriving meaning from the work is a challenge.\nThe work has no clear topic or narrative. The communication is confused, unclear, or inaccessible.\n\n\nConceptual understanding and Critical Reflection (25%)\nBoth the Article and Technical Appendix show exemplary understanding of the topic / wider issues associated with it and of the methods employed to interrogate the data. A clear understanding of any data / methodological shortcomings / issues / challenges is presented with a highly sophisticated degree of critical reflection in relation to the substantive topic and / or methods employed is demonstrated.\nArticle and Technical Appendix show excellent and highly competent conceptual understanding of key concepts and theories related to both the topic and methods employed. The work demonstrates a thorough understanding of the chosen example and recognises and reflects lucidly on any shortcomings and / or the wider significance of the findings in a way that is not contrived or formulaic but shows a sophisticated level of insight.\nArticle and Technical Appendix show good understanding of key concepts and theories related to both the topic and methods employed. The work demonstrates a sound understanding of the chosen example and recognises and reflects lucidly on any shortcomings and / or the wider significance of the findings in a way that is not contrived or formulaic but shows a sophisticated level of insight.\nArticle and Technical Appendix show basic understanding of key concepts and theories related to both the topic and methods employed. The work demonstrates a rudimentary understanding of the chosen example and recognises and may offer only some reflection on the shortcomings of the work or not at all / contrived at the bottom end.\nInadequate and insufficient conceptual understanding of key concepts and theories. The work demonstrates an invalid or lack of understanding of the concepts introduced. Any analysis attempted fails to support the observations made.\nNegligible or no conceptual understanding of key concepts and theories. The work demonstrates an irrelevant, inaccurate, confused, unclear, or inaccessible understanding of the concepts.\n\n\n\n\n\n\nThe purpose of this assessment is to test your understanding of the various methods introduced in this course and your ability to apply them appropriately to a topic of your choice. One of the differentiators at Masters level is the ability to think both creatively and critically while showing an awareness or knowledge of contemporary issues either in relation to your specific discipline of study or more widely. Being able to demonstrate how established techniques of research and enquiry can be used to create and interpret knowledge is at the core of Masters level thinking and this assessment piece. The ability to demonstrate self-direction (in choosing an appropriate topic for this assessment) and to think autonomously in designing your own article.\n\nMark Scheme – Explained\nLevel 7 Descriptors - https://www.qaa.ac.uk/docs/qaa/quality-code/the-frameworks-for-higher-education-qualifications-of-uk-degree-awarding-bodies-2024.pdf - p26\nMaster’s degree\nThe descriptor provided for this level of the Frameworks is for any master’s degree which should meet the descriptor in full. This qualification descriptor should also be used as a reference point for other qualifications at Level 7 on the FHEQ/SCQF Level 11 on the FQHEIS, including postgraduate certificates and postgraduate diplomas.\nMaster’s degrees are awarded to students who have demonstrated:\n•         a systematic understanding of knowledge, and a critical awareness of current problems and/or new insights, much of which is at, or informed by, the forefront of their academic discipline, field of study or area of professional practice\n•         a comprehensive understanding of techniques applicable to their own research or advanced scholarship\n•         originality in the application of knowledge, together with a practical understanding of how established techniques of research and enquiry are used to create and interpret knowledge in the discipline\n•         conceptual understanding that enables the student:\n•         to evaluate critically current research and advanced scholarship in the discipline\n•         to evaluate methodologies and develop critiques of them and, where appropriate, to propose new hypotheses.\nTypically, holders of the qualification will be able to:\n•         deal with complex issues - both systematically and creatively, make sound judgements in the absence of complete data, and communicate their conclusions clearly to specialist and non-specialist audiences\n•         demonstrate self-direction and originality in tackling and solving problems, and act autonomously in planning and implementing tasks at a professional or equivalent level\n•         continue to advance their knowledge and understanding, and to develop new skills to a high level. \nAnd holders will have:\n•         the qualities and transferable skills necessary for employment requiring:  \n•         the exercise of initiative and personal responsibility\n•         decision-making in complex and unpredictable situations\n•         the independent learning ability required for continuing professional development.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome",
    "section": "",
    "text": "The Quantitative Methods (QM) module is a compulsory element of CASA’s MSc/MRes USS programmes and is intended provide an introduction to quantitative methods for all students.\nAs data becomes central to decision-making across all sectors, the ability to move beyond simple description to robust and evidence-based analysis is essential for researchers and practitioners in geography and urban studies. Making sense of the complex patterns that define our world requires a firm understanding of the language of data. This module provides the essential grammar for that language and aims to equip students with the foundational quantitative skills needed to describe data, build models, and derive meaningful insights from numerical evidence.\nTo achieve this, the module is structured progressively across three core sections. The first section establishes the fundamental toolkit for quantitative analysts. Beginning with Exploratory Data Analysis, students will learn how to visualise, summarise, and critically interrogate datasets. This is followed by a rigorous grounding in the principles of statistical inference through hypothesis testing, and an introduction to the linear algebra that provides the mathematical architecture for many of the models used in modern data science.\nThe second section builds upon this foundation to explore the core of statistical modelling: understanding and quantifying relationships between variables. Students will progress from measuring correlations to building sophisticated regression models. The curriculum covers the workhorse of social science, the Generalised Linear Model (GLM), before advancing to Multilevel Models, a critical technique for handling the nested and hierarchical data that is common in geographical and social research.\nThe final section of the course introduces advanced techniques for uncovering hidden structures within complex, high-dimensional datasets. Students will learn methods for dimensionality reduction to simplify complexity without losing vital information, and clustering analysis to identify natural groupings and patterns in data.\nTherefore, this module guides students on a complete analytical journey, from foundational principles to the application of advanced modelling techniques. It serves as a vital prerequisite for more specialised analytical modules and is essential for students wishing to undertake quantitative geospatial research. Ultimately, this module will provide quantitative skills that are in high demand across public, private, and academic sectors."
  },
  {
    "objectID": "index.html#acknowledgements",
    "href": "index.html#acknowledgements",
    "title": "Welcome",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nWe really appreciate the support from various people:\n\nJon for setting up this wonderful CASA-themed quarto template.\nOllie and Andy for inspiring us to pursue a Quarto-based module website."
  },
  {
    "objectID": "sessions/week1.html",
    "href": "sessions/week1.html",
    "title": "Week 1",
    "section": "",
    "text": "This week will introduce data types and key metrics for describing and representing data.",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#introduction",
    "href": "sessions/week1.html#introduction",
    "title": "Week 1",
    "section": "",
    "text": "This week will introduce data types and key metrics for describing and representing data.",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#learning-objectives",
    "href": "sessions/week1.html#learning-objectives",
    "title": "Week 1",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nUnderstand data types for quantitative research.\nDescribe and represent data using key metrics.\nVisualise data with boxplot.",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#lecture",
    "href": "sessions/week1.html#lecture",
    "title": "Week 1",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#quiz",
    "href": "sessions/week1.html#quiz",
    "title": "Week 1",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#practical",
    "href": "sessions/week1.html#practical",
    "title": "Week 1",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1.html#further-resources",
    "href": "sessions/week1.html#further-resources",
    "title": "Week 1",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 1: Basics",
      "1. Explanatory Data Analysis #1"
    ]
  },
  {
    "objectID": "sessions/week1_lecture.html#understanding-and-describing-data",
    "href": "sessions/week1_lecture.html#understanding-and-describing-data",
    "title": "Exploratory Data Analysis #1",
    "section": "Understanding and describing data",
    "text": "Understanding and describing data\n\nQuantitative research is the process of collecting and analysing numerical data to describe, model, and predict variables of interest.\nGarbage in, garbage out.\n\n\nThis lecture focuses on understanding and describing data."
  },
  {
    "objectID": "sessions/week1_lecture.html#learning-objectives",
    "href": "sessions/week1_lecture.html#learning-objectives",
    "title": "Exploratory Data Analysis #1",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nUnderstand basic data types;\nConsider how to summarise and represent data."
  },
  {
    "objectID": "sessions/week1_lecture.html#four-levels-of-measurements",
    "href": "sessions/week1_lecture.html#four-levels-of-measurements",
    "title": "Exploratory Data Analysis #1",
    "section": "Four levels of measurements",
    "text": "Four levels of measurements\n\n\n\n\nNominal\nOrdinal\nInterval\nRatio\n\n\n\n\nCategorizes and labels variables\n✔\n✔\n✔\n✔\n\n\nRanks categories in order\n\n✔\n✔\n✔\n\n\nHas known, equal intervals\n\n\n✔\n✔\n\n\nHas a true or meaningful zero\n\n\n\n✔\n\n\n\n\nDeveloped by psychologist Stanley Smith Stevens (1906 - 1973)"
  },
  {
    "objectID": "sessions/week1_lecture.html#nominal",
    "href": "sessions/week1_lecture.html#nominal",
    "title": "Exploratory Data Analysis #1",
    "section": "Nominal",
    "text": "Nominal\n\nDifferentiates items based only on names; no order between them.\nAlso called categorical data\nExample: colour, gender, country names\nWhat can be said about them?\n\nEquality: ‘apple’ is not ‘pear’, ‘apple’ is ‘apple’\nMode: the most common item"
  },
  {
    "objectID": "sessions/week1_lecture.html#ordinal",
    "href": "sessions/week1_lecture.html#ordinal",
    "title": "Exploratory Data Analysis #1",
    "section": "Ordinal",
    "text": "Ordinal\n\nAllow for rank order, but not the relative degree of difference\nExample: measurement of opinions\n\ncompletely agree\nmostly agree\nneither degree nor disagree\nmostly disagree\ncompletely disagree\n\nWhat can be said about them?\n\n✅ Equality; mode\n✅ Median: middle-ranked item\n❌ Differences between two levels; arithmetic mean"
  },
  {
    "objectID": "sessions/week1_lecture.html#interval",
    "href": "sessions/week1_lecture.html#interval",
    "title": "Exploratory Data Analysis #1",
    "section": "Interval",
    "text": "Interval\n\nAllow for degree of difference between items, but not the ratio\nThe zero value is arbitrary\nExample: Celsius temperature\n\nDefinition: define 0°C & 100°C, and then separate them into 100 intervals.\nDepends on altitude/elevation\n\nWhat can be said about them?\n\n✅ equality, mode, median\n✅ addition, arithmetic mean\n❌ ratio (100°C is NOT twice 50°C)"
  },
  {
    "objectID": "sessions/week1_lecture.html#interval-1",
    "href": "sessions/week1_lecture.html#interval-1",
    "title": "Exploratory Data Analysis #1",
    "section": "Interval",
    "text": "Interval\n\nAnother example: longtitude & latitude coordinates\nThe coordinate of 8 is twice as far as that of 4? ❌"
  },
  {
    "objectID": "sessions/week1_lecture.html#ratio",
    "href": "sessions/week1_lecture.html#ratio",
    "title": "Exploratory Data Analysis #1",
    "section": "Ratio",
    "text": "Ratio\n\nAllow for ratio between items\nThe zero value is unique and non-arbitrary.\nExample: mass, length, energy\nWhat can be said about them?\n\n✅ Equality, mode, median, arithmetic mean\n✅ Ratio (2kg is twice as heavy as 1kg)"
  },
  {
    "objectID": "sessions/week1_lecture.html#notes",
    "href": "sessions/week1_lecture.html#notes",
    "title": "Exploratory Data Analysis #1",
    "section": "Notes",
    "text": "Notes\n\n‘Encoding’ does not change the nature of a measurement.\nGender variable (male, female, others) is NOMINAL.\nIf this variable is encodeded {male:0, female:1, others:2}, is it NOMINAL, or INTERVAL?"
  },
  {
    "objectID": "sessions/week1_lecture.html#another-categorisation-numerical-vs.-categorical",
    "href": "sessions/week1_lecture.html#another-categorisation-numerical-vs.-categorical",
    "title": "Exploratory Data Analysis #1",
    "section": "Another categorisation: numerical vs. categorical",
    "text": "Another categorisation: numerical vs. categorical\n\n\n\n\n\n\n\n\nType\nCategory\nNotes\n\n\n\n\nQuantitative (numerical) data\nDiscrete data\nOnly in whole numbers, e.g. number of staffs\n\n\n\nContinuous data\ne.g. temperature, 23°C, 23.4°C\n\n\nQualitative (categorical) data\nNominal\nSame as nominal in ‘Levels of measurement’\n\n\n\nOrdinal\nSee above"
  },
  {
    "objectID": "sessions/week1_lecture.html#quiz-time",
    "href": "sessions/week1_lecture.html#quiz-time",
    "title": "Exploratory Data Analysis #1",
    "section": "Quiz time",
    "text": "Quiz time\n\nMentimeter quiz"
  },
  {
    "objectID": "sessions/week1_lecture.html#key-metrics",
    "href": "sessions/week1_lecture.html#key-metrics",
    "title": "Exploratory Data Analysis #1",
    "section": "Key metrics",
    "text": "Key metrics\n\n\n\nQuantity\nThe middle\nThe spread"
  },
  {
    "objectID": "sessions/week1_lecture.html#us-city-population",
    "href": "sessions/week1_lecture.html#us-city-population",
    "title": "Exploratory Data Analysis #1",
    "section": "US city population",
    "text": "US city population\n\n\n\nQuantity: 282 values\nThe middle: Mean 302869.3\nThe middle: Median 167744.5 (Very different from mean)\nThe middle: Mode 106433 (Useful? ❌)\nShould use mean or median? median is better than mean, as data is unlikely normal distributed"
  },
  {
    "objectID": "sessions/week1_lecture.html#variance-quantifying-spread",
    "href": "sessions/week1_lecture.html#variance-quantifying-spread",
    "title": "Exploratory Data Analysis #1",
    "section": "Variance: quantifying spread",
    "text": "Variance: quantifying spread\nDenote city population by \\([y_1, y_2, ..., y_n]\\) and variance by \\(\\sigma^2\\)\n\\[\n\\begin{aligned}\n\\sigma^2 &= \\frac{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}{n} \\\\\n&= \\frac{(y_1 - \\bar{y})^2 + (y_2 - \\bar{y})^2 + \\dots + (y_n - \\bar{y})^2}{n}\n\\end{aligned}\n\\]\nA large variance means considerable spreadedness in data."
  },
  {
    "objectID": "sessions/week1_lecture.html#standard-deviation-sigma",
    "href": "sessions/week1_lecture.html#standard-deviation-sigma",
    "title": "Exploratory Data Analysis #1",
    "section": "Standard deviation \\(\\sigma\\)",
    "text": "Standard deviation \\(\\sigma\\)\n\\[\n\\begin{aligned}\n\\text{Standard Deviation} = \\sqrt{\\text{Variance}}\n\\end{aligned}\n\\]\n\nUnit: if \\(y\\) is in unit of meter (m), then St. Dev is in unit of m, variance in unit of \\(\\text{m}^2\\)"
  },
  {
    "objectID": "sessions/week1_lecture.html#summary-of-key-metrics",
    "href": "sessions/week1_lecture.html#summary-of-key-metrics",
    "title": "Exploratory Data Analysis #1",
    "section": "Summary of key metrics",
    "text": "Summary of key metrics\n\n\nQuantity\nThe middle: mean, median, mode\nThe spread: variance, standard deviation\nVisualising data is also important: BOXPLOT!\nPlease check two types of SPECIAL VALUES before computing these metrics."
  },
  {
    "objectID": "sessions/week1_lecture.html#ft-visual-vocabulary",
    "href": "sessions/week1_lecture.html#ft-visual-vocabulary",
    "title": "Exploratory Data Analysis #1",
    "section": "FT visual vocabulary",
    "text": "FT visual vocabulary\n\nhttps://ft-interactive.github.io/visual-vocabulary/"
  },
  {
    "objectID": "sessions/week1_lecture.html#boxplot-for-a-dataset",
    "href": "sessions/week1_lecture.html#boxplot-for-a-dataset",
    "title": "Exploratory Data Analysis #1",
    "section": "Boxplot for a dataset",
    "text": "Boxplot for a dataset\n\nShowing distribution of a dataset"
  },
  {
    "objectID": "sessions/week1_lecture.html#boxplot-for-comparing-multiple-datasets",
    "href": "sessions/week1_lecture.html#boxplot-for-comparing-multiple-datasets",
    "title": "Exploratory Data Analysis #1",
    "section": "Boxplot for comparing multiple datasets",
    "text": "Boxplot for comparing multiple datasets"
  },
  {
    "objectID": "sessions/week1_lecture.html#when-boxplot-fails",
    "href": "sessions/week1_lecture.html#when-boxplot-fails",
    "title": "Exploratory Data Analysis #1",
    "section": "When boxplot fails?",
    "text": "When boxplot fails?\n\nWhen there are lots of ‘outliers’ in the data\nWhat are ‘Outliers’?"
  },
  {
    "objectID": "sessions/week1_lecture.html#null-values",
    "href": "sessions/week1_lecture.html#null-values",
    "title": "Exploratory Data Analysis #1",
    "section": "Null values",
    "text": "Null values\n\nRepresenting the absence of data or an unknow value\nDifferent from zero or a blank space\nNull values should be excluded before computing mean or std"
  },
  {
    "objectID": "sessions/week1_lecture.html#null-island-in-geography",
    "href": "sessions/week1_lecture.html#null-island-in-geography",
    "title": "Exploratory Data Analysis #1",
    "section": "Null island in geography",
    "text": "Null island in geography\n\nlong=0, lat=0. Not even an island!\nIt became famous because some software assigned “0,0” for long-lat when location is missing\nMany events were mapped to this one, including lots on Strava\nSource: wikipedia.org"
  },
  {
    "objectID": "sessions/week1_lecture.html#outliers",
    "href": "sessions/week1_lecture.html#outliers",
    "title": "Exploratory Data Analysis #1",
    "section": "Outliers",
    "text": "Outliers\n\nA data point that differs significantly from other observations\nThere are three types of outliers\nPlease explain the rationale for removing any identified outliers, including the criteria and methods used"
  },
  {
    "objectID": "sessions/week1_lecture.html#outliers-1",
    "href": "sessions/week1_lecture.html#outliers-1",
    "title": "Exploratory Data Analysis #1",
    "section": "Outliers",
    "text": "Outliers\n\n\n\n\n\n\n\n\nType\nSource\nHandling\n\n\n\n\nError Outliers\nFrom mistakes in data collection/entry/measurement, e.g. a temperature sensor reading 500 °C\nShould be corrected or removed\n\n\nIrregular Pattern Outliers\n\n\n\n\nInfluential Outliers"
  },
  {
    "objectID": "sessions/week1_lecture.html#outliers-2",
    "href": "sessions/week1_lecture.html#outliers-2",
    "title": "Exploratory Data Analysis #1",
    "section": "Outliers",
    "text": "Outliers\n\n\n\n\n\n\n\n\nType\nSource\nHandling\n\n\n\n\nError Outliers\n\n\n\n\nIrregular Pattern Outliers\nGenuinely occur, but do not follow general pattern or relationship in the dataset, e.g. sudden spikes in sales in Black Friday\nThey might indicate unusual events or anomalies worth investigating. If the purpose is to study overall pattern, they should be removed\n\n\nInfluential Outliers"
  },
  {
    "objectID": "sessions/week1_lecture.html#outliers-3",
    "href": "sessions/week1_lecture.html#outliers-3",
    "title": "Exploratory Data Analysis #1",
    "section": "Outliers",
    "text": "Outliers\n\n\n\n\n\n\n\n\nType\nSource\nHandling\n\n\n\n\nError Outliers\n\n\n\n\nIrregular Pattern Outliers\n\n\n\n\nInfluential Outliers\nAppear extreme but are integral to the underlying pattern or model, e.g. NYC in US city population data\nShould keep them, as removing them could distort the analysis or overlook important features of the data"
  },
  {
    "objectID": "sessions/week1_lecture.html#detecting-outlier-interquartile-range-iqr",
    "href": "sessions/week1_lecture.html#detecting-outlier-interquartile-range-iqr",
    "title": "Exploratory Data Analysis #1",
    "section": "Detecting outlier: interquartile range (IQR)",
    "text": "Detecting outlier: interquartile range (IQR)"
  },
  {
    "objectID": "sessions/week1_lecture.html#quiz-which-type-of-outliers",
    "href": "sessions/week1_lecture.html#quiz-which-type-of-outliers",
    "title": "Exploratory Data Analysis #1",
    "section": "Quiz: which type of outliers?",
    "text": "Quiz: which type of outliers?\n\nerror vs. irregular pattern vs. influential\n\n\nIn building height data, 10-storey building with 1m height\nIn gender ratios of countries data, Vatican City with gender ratio of 7:1\nIn UK city GDP data, GDP of Greater London"
  },
  {
    "objectID": "sessions/week1_lecture.html#summary-describing-a-dataset",
    "href": "sessions/week1_lecture.html#summary-describing-a-dataset",
    "title": "Exploratory Data Analysis #1",
    "section": "Summary: describing a dataset",
    "text": "Summary: describing a dataset\n\nKey metrics\nNull values and outliers (and handle them!)\nVisualising data"
  },
  {
    "objectID": "sessions/week2.html",
    "href": "sessions/week2.html",
    "title": "Week 2",
    "section": "",
    "text": "This week will introduce key probability distributions.",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#introduction",
    "href": "sessions/week2.html#introduction",
    "title": "Week 2",
    "section": "",
    "text": "This week will introduce key probability distributions.",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#learning-objectives",
    "href": "sessions/week2.html#learning-objectives",
    "title": "Week 2",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nDescribe the characteristic features of common probability distributions.\nCalculate exponentials and logarithms.\nEvaluate whether a dataset is representative.",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#lecture",
    "href": "sessions/week2.html#lecture",
    "title": "Week 2",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#quiz",
    "href": "sessions/week2.html#quiz",
    "title": "Week 2",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#practical",
    "href": "sessions/week2.html#practical",
    "title": "Week 2",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2.html#further-resources",
    "href": "sessions/week2.html#further-resources",
    "title": "Week 2",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 1: Basics",
      "2. Explanatory Data Analysis #2"
    ]
  },
  {
    "objectID": "sessions/week2_practical.html",
    "href": "sessions/week2_practical.html",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "",
    "text": "This week is focussed on using some common functions in Python to plot data and distributions."
  },
  {
    "objectID": "sessions/week2_practical.html#learning-outcomes",
    "href": "sessions/week2_practical.html#learning-outcomes",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\n\nFamiliarise yourself with opening data files in Python.\nFamiliarise yourself with plotting histograms of data in Python."
  },
  {
    "objectID": "sessions/week2_practical.html#loading-the-data",
    "href": "sessions/week2_practical.html#loading-the-data",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "Loading the data",
    "text": "Loading the data\nWe are going to look at schools perfomance data in England.\nThe data is sourced from  and is downloadable here.\nWe have saved a copy of this dataset to the Github repo, in case that the dataset is removed from the website.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np \n\n# Read CSV file, handling common missing value entries\nna_vals = [\"\", \"NA\", \"SUPP\", \"NP\", \"NE\", \"SP\", \"SN\", \"SUPPMAT\"]\ndf_ks4 = pd.read_csv(\n    'L2_data/england_ks4final.csv',\n    na_values = na_vals\n)\n\ninfo_cols = ['RECTYPE', 'LEA', 'SCHNAME', 'TOTPUPS']\nebaccs_cols = ['EBACCAPS', 'EBACCAPS_LO', 'EBACCAPS_MID', 'EBACCAPS_HI']\n\ndf_ks4 = df_ks4[info_cols + ebaccs_cols]\n\ndf_ks4[['TOTPUPS']+ebaccs_cols] = df_ks4[['TOTPUPS']+ebaccs_cols].apply(pd.to_numeric, errors='coerce')\n\ndf_ks4.head()\n\n/tmp/ipykernel_12481/1207205982.py:7: DtypeWarning: Columns (75,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,144,145,146,147,148,149,150,151,152,177,178,179,180,181,182,183,186,187,188,189,190,191,192,194,195,196,198,199,200,202,203,204,206,207,208,210,211,212,214,215,216,218,219,220,222,223,224,230,233,234,235,236,237,238,239,242,243,244,245,246,247,248,251,252,253,254,255,256,257,266,267,268,269,270,271,272,281,282,283,284,285,286,287,296,297,298,299,300,301,302,311,312,313,314,315,316,317,335,336,337,340,341,342,345,346,347,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410) have mixed types. Specify dtype option on import or set low_memory=False.\n  df_ks4 = pd.read_csv(\n\n\n\n\n\n\n\n\n\nRECTYPE\nLEA\nSCHNAME\nTOTPUPS\nEBACCAPS\nEBACCAPS_LO\nEBACCAPS_MID\nEBACCAPS_HI\n\n\n\n\n0\n1\n201.0\nCity of London School\n1045.0\n2.10\nNaN\nNaN\nNaN\n\n\n1\n1\n201.0\nCity of London School for Girls\n739.0\n1.51\nNaN\nNaN\nNaN\n\n\n2\n1\n201.0\nDavid Game College\n365.0\n0.56\nNaN\nNaN\nNaN\n\n\n3\n4\n201.0\nNaN\n0.0\nNaN\nNaN\nNaN\nNaN\n\n\n4\n1\n202.0\nAcland Burghley School\n1163.0\n4.62\n1.91\n3.81\n6.87\n\n\n\n\n\n\n\nYou might be wondering why I’ve chosen the columns info_cols and ebaccs_cols.\nLooking at the metadata (which you can see in ‘L2_data/ks4_meta.xlsx’) we can see the full meaning of each column header:\n\n‘RECTYPE’ = Record type (1=mainstream school; 2=special school; 4=local authority; 5=National (all schools); 7=National (maintained schools))\n‘LEA’ = Local authority\n‘SCHNAME’ = School name\n‘TOTPUPS’ = Number of pupils on roll (all ages)\n‘EBACCAPS’ = Average EBacc APS score per pupil\n‘EBACCAPS_LO’ = Average EBacc APS score per pupil with low prior attainment\n‘EBACCAPS_MID’ = Average EBacc APS score per pupil with middle prior attainment\n‘EBACCAPS_HI’ = Average EBacc APS score per pupil with high prior attainment\n\nThe EBacc is a measure of students school grades calculated as an avergae score across a set number of subjects. It is used as a performance indicator of English schools. You can read more about it here."
  },
  {
    "objectID": "sessions/week2_practical.html#describing-the-dataframe",
    "href": "sessions/week2_practical.html#describing-the-dataframe",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "Describing the dataframe",
    "text": "Describing the dataframe\n\nCheck how much data is missing\n\n# print how much data is missing for each column\ndf_ks4.isna().mean() * 100 \n\nRECTYPE          0.000000\nLEA              0.034406\nSCHNAME          2.683640\nTOTPUPS          1.221400\nEBACCAPS        17.684500\nEBACCAPS_LO     38.775159\nEBACCAPS_MID    41.149148\nEBACCAPS_HI     42.490969\ndtype: float64\n\n\nIt seems suspiscious that the school names are missing for some of the entries - let’s check these.\n\n# return rows where SCHNAME is missing\ndf_ks4[df_ks4['SCHNAME'].isna()]\n\n\n\n\n\n\n\n\nRECTYPE\nLEA\nSCHNAME\nTOTPUPS\nEBACCAPS\nEBACCAPS_LO\nEBACCAPS_MID\nEBACCAPS_HI\n\n\n\n\n3\n4\n201.0\nNaN\n0.0\nNaN\nNaN\nNaN\nNaN\n\n\n24\n4\n202.0\nNaN\n10865.0\n4.36\n2.03\n4.19\n6.33\n\n\n55\n4\n203.0\nNaN\n18998.0\n4.13\n2.14\n4.21\n5.77\n\n\n88\n4\n204.0\nNaN\n15214.0\n4.72\n2.32\n4.64\n6.72\n\n\n112\n4\n205.0\nNaN\n9905.0\n5.12\n2.26\n4.93\n6.90\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n5748\n4\n941.0\nNaN\n31801.0\n3.96\n2.16\n4.04\n6.08\n\n\n5776\n4\n942.0\nNaN\n17442.0\n3.81\n2.08\n3.85\n5.54\n\n\n5810\n4\n943.0\nNaN\n14503.0\n3.97\n2.29\n3.81\n5.80\n\n\n5811\n5\nNaN\nNaN\n4129401.0\n3.88\nNaN\nNaN\nNaN\n\n\n5812\n7\nNaN\nNaN\n3688033.0\n4.05\n2.07\n4.05\n6.09\n\n\n\n\n156 rows × 8 columns\n\n\n\nSo, these are all record type 4, 5, or 7 - i.e. they’re not individual schools! Let’s limit the selection to only mainstream and special schools.\n\n# only keep rows where RECTYPE is 1 or 2 \ndf_ks4 = df_ks4[df_ks4['RECTYPE'].isin([1, 2])].copy()\n\nNow we can check the data dimensions.\n\nrows, cols = df_ks4.shape\nprint(f\"Rows: {rows}, Columns: {cols}\")\n\nRows: 5657, Columns: 8\n\n\n\n\nSummary statistics\nWe can use the describe function in pandas to easily get the summary statistics for a dataframe.\n\nnumerical_cols = ['TOTPUPS', 'EBACCAPS', 'EBACCAPS_LO', 'EBACCAPS_MID', 'EBACCAPS_HI']\n\ndf_ks4[numerical_cols].describe()\n\n\n\n\n\n\n\n\nTOTPUPS\nEBACCAPS\nEBACCAPS_LO\nEBACCAPS_MID\nEBACCAPS_HI\n\n\n\n\ncount\n5586.000000\n4631.000000\n3406.000000\n3268.000000\n3190.000000\n\n\nmean\n735.296097\n3.428538\n2.090628\n4.033562\n5.782893\n\n\nstd\n552.209689\n1.679245\n0.769925\n0.818922\n0.856998\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.100000\n0.590000\n\n\n25%\n165.000000\n2.820000\n1.830000\n3.560000\n5.250000\n\n\n50%\n761.000000\n3.700000\n2.200000\n3.980000\n5.820000\n\n\n75%\n1149.000000\n4.440000\n2.520000\n4.470000\n6.350000\n\n\nmax\n3440.000000\n8.700000\n5.320000\n7.170000\n8.730000"
  },
  {
    "objectID": "sessions/week2_practical.html#histograms",
    "href": "sessions/week2_practical.html#histograms",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "Histograms",
    "text": "Histograms\nLet’s try plotting the Average EBacc APS score per pupil.\n\nn_bins = 10\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.hist(df_ks4['EBACCAPS'].dropna(), bins=n_bins, color='#abc766', edgecolor='black')\nax.set_title('EBacc distribution')\nax.set_xlabel('EBacc score')\nax.set_ylabel('Number of schools')  \nax.set_xlim(0,9) # the EBacc has a maximum score of 9\n\nplt.show()\n\n\n\n\n\n\n\n\nWhat do you observe from this boxplot? Because the bins are quite large it’s difficult to get a sense of the distribution - try changing this to get a better idea of the data spread.\n\nQuestionAnswer\n\n\nn_bins = ??\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.hist(df_ks4['EBACCAPS'].dropna(), bins=n_bins, color='#abc766', edgecolor='black')\nax.set_title('EBacc distribution')\nax.set_xlabel('EBacc score')\nax.set_ylabel('Number of schools')  \nax.set_xlim(0,9) # the EBacc has a maximum score of 9\n\nplt.show()\n\n\nn_bins = 30\nfig, ax = plt.subplots(figsize=(12, 8))\n\nax.hist(df_ks4['EBACCAPS'].dropna(), bins=n_bins, color='#abc766', edgecolor='black')\nax.set_title('EBacc distribution')\nax.set_xlabel('EBacc score')\nax.set_ylabel('Number of schools')  \nax.set_xlim(0,9) # the EBacc has a maximum score of 9\n\nplt.show()\n\n\n\n\n\nIs it normally distributed?\nLooking at the histogram does the data look normally distributed?\nRemember the key features of the normal distribution:\n\nData is continuous\n\nit is something you measure not something you count\n\nData is equally likely to be larger or smaller than average\n\nsymmetric\n\nCharacteristic size, all data points are close to the mean\n\nsingle peak\n\nThere is less data further away from the mean\n\nsmooth tails on both sides\n\n\nOne way to consider whether it is normally distributed is to overlay the normal distribution on top.\nWe can use the package scipy.stats which has functions for generating probability density functions for common distributions. You can see which common distributions here.\n\nimport scipy.stats as sps\n\n# first let's get the mean and stand deviation \nmu = df_ks4['EBACCAPS'].dropna().mean()\nstd = df_ks4['EBACCAPS'].dropna().std()\n\n## Create the plot \n\n# plot the histogram\nplt.figure(figsize=(12, 8))\nplt.hist(df_ks4['EBACCAPS'], bins=30, density=True, color='#abc766', edgecolor='black')\n\n# plot the Probability Density Function (PDF)\nxmin = 0 \nxmax = 9\nx = np.linspace(xmin, xmax, 100)\np = sps.norm.pdf(x, mu, std)\nplt.plot(x, p, 'k', linewidth=2, color=\"#e16fca\")\n\nplt.title(f\"Fit results: $\\mu$ = {mu:.2f},  $\\sigma$ = {std:.2f}\")\nplt.xlim(0, 9)\nplt.xlabel(\"EBacc score\")\nplt.ylabel(\"Density\")\n\nplt.show()\n\n/tmp/ipykernel_12481/2445938851.py:18: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"k\" (-&gt; color=(0.0, 0.0, 0.0, 1)). The keyword argument will take precedence.\n  plt.plot(x, p, 'k', linewidth=2, color=\"#e16fca\")\n\n\n\n\n\n\n\n\n\nNote that this time we plot the histogram with density=True - this scales the histogram data."
  },
  {
    "objectID": "sessions/week2_practical.html#youre-done",
    "href": "sessions/week2_practical.html#youre-done",
    "title": "Practical 2: Recognising and plotting probability distributions",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take your time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/week3_lecture.html#overview-of-lecture-2",
    "href": "sessions/week3_lecture.html#overview-of-lecture-2",
    "title": "Hypothesis Testing",
    "section": "Overview of lecture 2",
    "text": "Overview of lecture 2\nContinued concepts from data analysis, in particular probability distributions.\n\nRepresentative data\nNormal distribution\nBinomial distribution\nPoisson distribution\nExponentials\nLogarithms"
  },
  {
    "objectID": "sessions/week3_lecture.html#what-is-the-likelihood-of-events-occuring",
    "href": "sessions/week3_lecture.html#what-is-the-likelihood-of-events-occuring",
    "title": "Hypothesis Testing",
    "section": "What is the likelihood of events occuring?",
    "text": "What is the likelihood of events occuring?\nNOTE: add a picture here\nQuestion\n\nWhat is the probability of someone at UCL being over 190cm?\n\nHow can we try to answer this?\nTry to understand the distribution of heights.\n\nLast week we asked this question and we thought about the distribution of the data. How to describe the distribution of the data mathematically.\nThis week we look at how to properly ask the research question, and how to answer it."
  },
  {
    "objectID": "sessions/week3_lecture.html#hypothesising",
    "href": "sessions/week3_lecture.html#hypothesising",
    "title": "Hypothesis Testing",
    "section": "Hypothesising",
    "text": "Hypothesising\n\n\n\n\n\n\n\nResearch science is about coming up with hypotheses and evaluating them.\nIt’s iterative - as we find out new information we update our method and processes accordingly. (Gelman et al. 2020. Bayesian Workflow)\n\n\nThis lecture thinking about posing and answering research questions.\nYou come up with a great idea - then need to think considering the data is this idea plausibly true?\nLink to the idea of a Bayesian workflow - Gelman."
  },
  {
    "objectID": "sessions/week3_lecture.html#learning-objectives",
    "href": "sessions/week3_lecture.html#learning-objectives",
    "title": "Hypothesis Testing",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should be able to:\n\nEstablish a hypothesis for a given research project.\nDefine the Type I and Type II errors.\nEvaluate a hypothesis using appropriate statistical tests."
  },
  {
    "objectID": "sessions/week3_lecture.html#how-do-we-know-what-to-believe",
    "href": "sessions/week3_lecture.html#how-do-we-know-what-to-believe",
    "title": "Hypothesis Testing",
    "section": "How do we know what to believe?",
    "text": "How do we know what to believe?\nNOTE: change this to focus on the idea of using statistics to validate claims - i.e. what we see in the media or on the news.\n\nCrime rates across cities\nSpatial patterns of school achievement\nInequalities in access to transport\n\n\n\nWe see stories in the news, how do we know what to believe and what not to believe? This is where having an understanding of statistical tests can help us - we can evaluate claims to try and figure out which are/ aren’t statistically significant.\nStatisitical tests are frequently used in science to figure out if our findings are important or not - essentially a way to formally define a threshold of what is an interesting result vs, what isn’t an interesting result.\nA clearly defined, and reporducible way to evaluate findings."
  },
  {
    "objectID": "sessions/week3_lecture.html#research-question-vs.-hypothesis",
    "href": "sessions/week3_lecture.html#research-question-vs.-hypothesis",
    "title": "Hypothesis Testing",
    "section": "Research question vs. hypothesis",
    "text": "Research question vs. hypothesis\nResearch question\nA research question focuses on a specific problem.\nHypothesis\nA formal statement that you will seek to prove or disprove.\n\nThe hypothesis is something you can explicitly test, and come to a judgement about it’s truth value."
  },
  {
    "objectID": "sessions/week3_lecture.html#flip-a-coin",
    "href": "sessions/week3_lecture.html#flip-a-coin",
    "title": "Hypothesis Testing",
    "section": "Flip a coin",
    "text": "Flip a coin\n\n\n\nYou have a coin.\nYou think it’s a fair coin.\nYou toss it 10 times.\nIt comes up heads 7 times."
  },
  {
    "objectID": "sessions/week3_lecture.html#the-hypothesis",
    "href": "sessions/week3_lecture.html#the-hypothesis",
    "title": "Hypothesis Testing",
    "section": "The hypothesis",
    "text": "The hypothesis\nNOTE: add poll here - what do students think the hypothesis is?\n\n\n\nYou have a coin.\nYou think it’s a fair coin.\nYou toss it 10 times.\nIt comes up heads 7 times.\n\n\n\nThe hypothesis is that it is a fair coin."
  },
  {
    "objectID": "sessions/week3_lecture.html#what-question-can-you-ask",
    "href": "sessions/week3_lecture.html#what-question-can-you-ask",
    "title": "Hypothesis Testing",
    "section": "What question can you ask?",
    "text": "What question can you ask?\n\n\n\nYou have a coin.\nYou think it’s a fair coin.\nYou toss it 10 times.\nIt comes up heads 7 times.\n\n\n\nIs it a fair coin?\n\n\nWhat’s the probability that it’s fair?\n\n\nIf the coin is fair, how likely would it be to see 7 heads out of 10 flips?"
  },
  {
    "objectID": "sessions/week3_lecture.html#what-question-should-you-ask",
    "href": "sessions/week3_lecture.html#what-question-should-you-ask",
    "title": "Hypothesis Testing",
    "section": "What question should you ask?",
    "text": "What question should you ask?\n\n\n\nYou have a coin.\nYou think it’s a fair coin.\nYou toss it 10 times.\nIt comes up heads 7 times.\n\n\nCorrect formulation:\nIf the coin is fair, how likely would it be to see 7 heads out of 10 flips or an even more extreme result?\n\n\nInterested in the probability of seeing the event or something even more extreme."
  },
  {
    "objectID": "sessions/week3_lecture.html#step-1",
    "href": "sessions/week3_lecture.html#step-1",
    "title": "Hypothesis Testing",
    "section": "Step 1",
    "text": "Step 1\nDefine the null and alternative hypothesis\n\n\\(H_0\\) - the null hypothesis\n\nthis is the “status quo”\n\n\n\n\\(H_1\\) - the alternative hypothesis\n\nyour hypothesis\nit requires some evidence (data) to verify"
  },
  {
    "objectID": "sessions/week3_lecture.html#step-2",
    "href": "sessions/week3_lecture.html#step-2",
    "title": "Hypothesis Testing",
    "section": "Step 2",
    "text": "Step 2\nSet your significance level \\(\\alpha\\)\nThe significance level is the threshold below which you reject the null hypothesis.\n\nDecide what “too unlikely” means before you do the test.\nCommon choice is 5% significance\n\n\\(\\alpha = 0.05\\)\nThis means that if we see evidence that would have less than a 5% chance of occurring under the null hypothesis, then we reject the null hypothesis."
  },
  {
    "objectID": "sessions/week3_lecture.html#warning",
    "href": "sessions/week3_lecture.html#warning",
    "title": "Hypothesis Testing",
    "section": "WARNING",
    "text": "WARNING\nDecide what “too unlikely” means before you do the test\nNOTE: add the banned symbol here\n\notherwise considered ‘HARKing’\n\nHypothesising\nAfter\nthe\nResults\nare\nKnown\n\n\n\nIt’s important to decide on your significance level prior, as otherwise you might find an event which is significant at the 10% threshold and not at 5% - which could lead to bad scientific practise."
  },
  {
    "objectID": "sessions/week3_lecture.html#step-3",
    "href": "sessions/week3_lecture.html#step-3",
    "title": "Hypothesis Testing",
    "section": "Step 3",
    "text": "Step 3\nIdentify the evidence\n\n\nThis could mean collecting the data\nOr identifying a suitable exisiting dataset\n\n\nIn quant methods this normally means finding an open public dataset to use."
  },
  {
    "objectID": "sessions/week3_lecture.html#step-4",
    "href": "sessions/week3_lecture.html#step-4",
    "title": "Hypothesis Testing",
    "section": "Step 4",
    "text": "Step 4\nCalculate the p-value\nThe p-value is the probability of seeing the evidence, or something even more extreme, if the null hypothesis is true.\n\nCalculated according to the appropriate statistical test\nThe choice of test is determined by the research question and the data\n\n\nWe’ll come back to different types of statistical test later in the lecture"
  },
  {
    "objectID": "sessions/week3_lecture.html#step-5",
    "href": "sessions/week3_lecture.html#step-5",
    "title": "Hypothesis Testing",
    "section": "Step 5",
    "text": "Step 5\nCompare p-value with significance level\n\np-value \\(&gt; \\alpha\\)\n\nEvidence not that unlikely.\nNot enough evidence to reject \\(H_0\\).\n\np-value \\(\\leq \\alpha\\)\n\nEvidence very unlikely.\nReject \\(H_0\\) and accept \\(H_1\\)."
  },
  {
    "objectID": "sessions/week3_lecture.html#the-steps",
    "href": "sessions/week3_lecture.html#the-steps",
    "title": "Hypothesis Testing",
    "section": "The steps",
    "text": "The steps\nIn order to evaluate our hypothesis we just have to do the five steps:\n\nDefine the null and alternative hypothesis\nSet you significance level\nIdentify the evidence\nCalculate the p-value\nCompare p-value with hypothesis level"
  },
  {
    "objectID": "sessions/week3_lecture.html#type-i-error",
    "href": "sessions/week3_lecture.html#type-i-error",
    "title": "Hypothesis Testing",
    "section": "Type I error",
    "text": "Type I error\nThe true null hypothesis is incorrectly rejected.\nThe null hypothesis is true, but you get a false positive leading to you rejecting the null hypothesis.\nThis is also called a false positive.\nExample: In court a defendant is found guilty despite being innocent."
  },
  {
    "objectID": "sessions/week3_lecture.html#type-ii-error",
    "href": "sessions/week3_lecture.html#type-ii-error",
    "title": "Hypothesis Testing",
    "section": "Type II error",
    "text": "Type II error\nThe false null hypothesis is incorrectly accepted.\nThe null hypothesis is false, but you get a false negative result, leading you to accepting the null hypothesis.\nThis is also called a false negative.\nExample: In court a defendant is found innocent despite being guilty."
  },
  {
    "objectID": "sessions/week3_lecture.html#example-mammograms",
    "href": "sessions/week3_lecture.html#example-mammograms",
    "title": "Hypothesis Testing",
    "section": "Example: Mammograms",
    "text": "Example: Mammograms\n\n\n\nNHS offers breast cancer screening for all people with breasts between the ages of 50 and 70.\n\nThe idea is to screen all those in the population who are at high risk of breast cancer - in the hope they pick up results better.\nWhilst the tests are good they’re not 100% accurate."
  },
  {
    "objectID": "sessions/week3_lecture.html#example-screening-outcomes",
    "href": "sessions/week3_lecture.html#example-screening-outcomes",
    "title": "Hypothesis Testing",
    "section": "Example: Screening outcomes",
    "text": "Example: Screening outcomes\n\\(H_0:\\) The individual doesn’t have breast cancer. \\(H_1:\\) The individual does have breast cancer.\n\nFrom NHS digital.\nFalse positive\n\nIn 2020-2021, \\(4.0%\\) of those screened had an abnormal results and were referred for assessment.\nOf these, \\(77.1%\\) were found to not have breast cancer at follow up assessment.\nLeading to a false positive rate of \\(3.1%\\).\n\nFalse negative\n\nThose who had a negative screening but did in fact have breast cancer.\nHarder to calculate the false negative rate, as they might be diagnosed with breast cancer at any later point in time.\nStudies suggest the false negative rate could be as high as \\(20%\\).\n\n\nFalse positive is bad as you might pursue a healthcare treatment which is unecessary.\nFalse negative - in healthcare context this is the worst outcome - as goes undiagnosed and hence untreated."
  },
  {
    "objectID": "sessions/week3_lecture.html#matrix-of-errors",
    "href": "sessions/week3_lecture.html#matrix-of-errors",
    "title": "Hypothesis Testing",
    "section": "Matrix of errors",
    "text": "Matrix of errors\n\n\n\n\nPossible outcomes form a matrix. Have two good outcomes, and two bad outcomes which we want to look out for (these are the Type I and Type II errors).\nThis is something to bear in mind when we look at evaluating our hypotheses. How good is our data, so how reliable is our outcome?\nOften this language is used when evaluating the outcomes of an ML classification model. Where we report the quality of a model in terms of its rate of false positives and false negatives."
  },
  {
    "objectID": "sessions/week3_lecture.html#understanding-the-literature-and-the-context",
    "href": "sessions/week3_lecture.html#understanding-the-literature-and-the-context",
    "title": "Hypothesis Testing",
    "section": "Understanding the literature and the context",
    "text": "Understanding the literature and the context\nThe hypothesis should not come out of thin air.\n\nShould consider:\n\nWhat do you know about the context?\nWhat research have other people done?"
  },
  {
    "objectID": "sessions/week3_lecture.html#asking-ethical-hypothesis-questions",
    "href": "sessions/week3_lecture.html#asking-ethical-hypothesis-questions",
    "title": "Hypothesis Testing",
    "section": "Asking ethical hypothesis questions",
    "text": "Asking ethical hypothesis questions\nIt’s important to not make unethical assumptions in choosing the hypothesis.\n\nExample\nPolice profiling - assumes a correlation between ethnicity and crime\n\nUse contextual knowledge\nIs this causation?\nOr correlation linked to other factors?"
  },
  {
    "objectID": "sessions/week3_lecture.html#correlation-vs.-causation",
    "href": "sessions/week3_lecture.html#correlation-vs.-causation",
    "title": "Hypothesis Testing",
    "section": "Correlation vs. Causation",
    "text": "Correlation vs. Causation\nCorrelation: Two variables are statistically related, as one changes so does the other.\nCausation: One variable influences the other variable to occur.\n\nCausation implies correlation. BUT correlation does not imply causation!!!\n\nLots of things can be correlated BUT it doesn’t mean one event caused another."
  },
  {
    "objectID": "sessions/week3_lecture.html#aliens-and-librarians",
    "href": "sessions/week3_lecture.html#aliens-and-librarians",
    "title": "Hypothesis Testing",
    "section": "Aliens and librarians",
    "text": "Aliens and librarians\n\n\n\nImage credit: [Spurious Correlations](https://www.tylervigen.com/spurious/correlation/19598_google-searches-for-report-ufo-sighting_correlates-with_the-number-of-librarians-in-hawaii)\n\n\n\nIt’s a dumb example but it’s quite easy to find nonsense correlations between random variables. Can generate your own at the website spurious correlations."
  },
  {
    "objectID": "sessions/week3_lecture.html#correlation-is-not-causation",
    "href": "sessions/week3_lecture.html#correlation-is-not-causation",
    "title": "Hypothesis Testing",
    "section": "Correlation IS NOT causation",
    "text": "Correlation IS NOT causation\nYou might not know whether events are correlated, or causing each other.\n\n BUT\n\n\n\nThe point of the hypothesis test is to test your idea – but you should use your contextual understanding to come up with plausible (and ethical) initial questions."
  },
  {
    "objectID": "sessions/week3_lecture.html#the-point-of-the-scientific-method",
    "href": "sessions/week3_lecture.html#the-point-of-the-scientific-method",
    "title": "Hypothesis Testing",
    "section": "The point of the scientific method",
    "text": "The point of the scientific method\n\n\n\n\n\n\nIt’s a process\n\nquestion\ntest\nevaluate\nREPEAT!"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-1",
    "href": "sessions/week3_lecture.html#example---step-1",
    "title": "Hypothesis Testing",
    "section": "Example - step 1",
    "text": "Example - step 1\nDefine the null and alternative hypothesis\n\n\\(H_0\\): The mean height of male and female students is the same.\n\\(H_1\\): The mean height of male and female students is different."
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-2",
    "href": "sessions/week3_lecture.html#example---step-2",
    "title": "Hypothesis Testing",
    "section": "Example - step 2",
    "text": "Example - step 2\nSet your significance level\n\n\\(\\alpha = 0.05\\)"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-3",
    "href": "sessions/week3_lecture.html#example---step-3",
    "title": "Hypothesis Testing",
    "section": "Example - step 3",
    "text": "Example - step 3\nIdentify the evidence\n\n\nI’ve collected data from 198 students, as follows:\n\n\n\nGroup\nSample Size\nMean (cm)\nstd (cm)\n\n\n\n\nFemale students\n95\n170\n5\n\n\nMale students\n103\n180\n6"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-4",
    "href": "sessions/week3_lecture.html#example---step-4",
    "title": "Hypothesis Testing",
    "section": "Example - step 4",
    "text": "Example - step 4\nCalculate the p-value\nAha!\n\nWe need to know what statistical test to use!"
  },
  {
    "objectID": "sessions/week3_lecture.html#parametric-vs.-non-parametric-tests",
    "href": "sessions/week3_lecture.html#parametric-vs.-non-parametric-tests",
    "title": "Hypothesis Testing",
    "section": "Parametric vs. Non-parametric tests",
    "text": "Parametric vs. Non-parametric tests\nParametric Tests\n\nEvaluate hypothesis for specific parameters\nTypically have assumptions about the distribution\n\ne.g. assumed normal distribution\n\nContinuous data\n\n\nNon-parametric Tests\n\nEvaluate hypothesis for entire population distribution\nTypcially less assumptions on the distribution\nContinuous or discrete data"
  },
  {
    "objectID": "sessions/week3_lecture.html#deciding-on-a-test",
    "href": "sessions/week3_lecture.html#deciding-on-a-test",
    "title": "Hypothesis Testing",
    "section": "Deciding on a test",
    "text": "Deciding on a test\nNOTE: want a table here that guides you on how to choose an appropriate statistical test"
  },
  {
    "objectID": "sessions/week3_lecture.html#students-t-test",
    "href": "sessions/week3_lecture.html#students-t-test",
    "title": "Hypothesis Testing",
    "section": "Student’s T-test",
    "text": "Student’s T-test\n\n\nStudent’s T-test is used to compare the mean of a dataset.\n\nparametric statistical test\nassumes the data is normally distributed\n\n\n\n\n\nThis is William Sealy Gosset - he was **not** a student.\nImage credit: https://en.wikipedia.org/wiki/William_Sealy_Gosset#/media/File:William_Sealy_Gosset.jpg\n\n\n\n\nWilliam Gosset was working for Guinness brewing company when he came up with the t-test - but his company wanted his to publish under a pseudonym - hence ‘student’. He was comparing the chemical properties of different samples of barley."
  },
  {
    "objectID": "sessions/week3_lecture.html#students-t-test-one-sample",
    "href": "sessions/week3_lecture.html#students-t-test-one-sample",
    "title": "Hypothesis Testing",
    "section": "Student’s T-test: one sample",
    "text": "Student’s T-test: one sample\nTests whether the population mean is equal to a specific value or not\nNOTE: want a diagram showing this.\n\nThe test statistic is calculated as:\n\\[\\begin{align}\nt = \\frac{\\bar{x} - \\mu_{0}}{s / \\sqrt{n}}\n\\end{align}\\]\nwhere\n\n\\(\\bar{x}\\) is the sample mean\n\\(\\mu_{0}\\) is the hypothesised population mean\n\\(s\\) is the sample standard deviation\n\\(n\\) is the sample size"
  },
  {
    "objectID": "sessions/week3_lecture.html#students-t-test-two-sample",
    "href": "sessions/week3_lecture.html#students-t-test-two-sample",
    "title": "Hypothesis Testing",
    "section": "Student’s T-test: two sample",
    "text": "Student’s T-test: two sample\nTests if the population means for two different groups are equal or not.\nNOTE: want a diagram showing this. . . .\nThe test statistic is:\n\\[\\begin{align}\nt = \\frac{\\bar{x}_1 - \\bar{x}_2}{s_p \\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}}\n\\end{align}\\]\n\n\\(\\bar{x}_1, \\bar{x}_2\\) are the sample means of groups 1 and 2\n\\(n_1, n_2\\) are the sample sizes of groups 1 and 2\n\\(s_p\\) is the pooled standard deviation\n\n\n\\[\\begin{align}\ns_p = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n\\end{align}\\]\nwith \\(s_1, s_2\\) the sample standard deviations."
  },
  {
    "objectID": "sessions/week3_lecture.html#students-t-test-paired",
    "href": "sessions/week3_lecture.html#students-t-test-paired",
    "title": "Hypothesis Testing",
    "section": "Student’s T-test: paired",
    "text": "Student’s T-test: paired\nTests if the difference between paired measurements for a population is zero or not - normally used with longitudinal data.\nNOTE: want a diagram showing this.\n\nThe test statistic is:\n\\[\\begin{align}\nt = \\frac{\\bar{d}}{s_d / \\sqrt{n}}\n\\end{align}\\]\nwhere\n\n\\(\\bar{d}\\) is the mean of the paired differences\n\\(s_d\\) is the standard deviation of the paired differences\n\\(n\\) is the number of pairs\n\n\nFor example used when I have data from different years, and want to figure out if there’s a difference across the years.\nYou need to be able to pair the data - i.e. the same things being observed at time point 1 and time point 2."
  },
  {
    "objectID": "sessions/week3_lecture.html#how-many-tails",
    "href": "sessions/week3_lecture.html#how-many-tails",
    "title": "Hypothesis Testing",
    "section": "How many tails",
    "text": "How many tails\nTests can be one-tailed or two-tailed - which you want is determined when you define the hypothesis.\nOne tailed: if you only care is the mean is significant in one direction Two tailed: if you care about the mean being different regardless of direction"
  },
  {
    "objectID": "sessions/week3_lecture.html#kolmogorov-smirnov",
    "href": "sessions/week3_lecture.html#kolmogorov-smirnov",
    "title": "Hypothesis Testing",
    "section": "Kolmogorov-Smirnov",
    "text": "Kolmogorov-Smirnov\nNOTE: want a diagram showing this.\n\nCompares two probability distributions\nCan be used to test whether an observed sample came from a given distribution\nOr to test whether two samples both came from the same distribution\n\n\nNamed after two Russian soviet mathematicians working in the mid 20th century"
  },
  {
    "objectID": "sessions/week3_lecture.html#k-s-test-one-sample-test",
    "href": "sessions/week3_lecture.html#k-s-test-one-sample-test",
    "title": "Hypothesis Testing",
    "section": "K-S test: one sample test",
    "text": "K-S test: one sample test\nThe Kolmogorov–Smirnov test statistic is:\n\\[\\begin{align}\nD_n = \\sup_x \\, | F_n(x) - F(x) |\n\\end{align}\\]\nwhere\n\n\\(F_n(x)\\) is the empirical distribution function (EDF) of the sample\n\\(F(x)\\) is the cumulative distribution function (CDF) of the reference distribution\n\n\n\nNote\n‘\\(sup\\)’ is the suprenum - think of it as the smallest upper bound."
  },
  {
    "objectID": "sessions/week3_lecture.html#k-s-empirical-distribution-function",
    "href": "sessions/week3_lecture.html#k-s-empirical-distribution-function",
    "title": "Hypothesis Testing",
    "section": "K-S: empirical distribution function",
    "text": "K-S: empirical distribution function\nThe empirical distribution function (EDF) is:\n\\[\\begin{align}\nF_{n}(x) = \\frac{1}{n} \\sum_{i=1}^{n} 1_{(-\\infty ,x]}(X_{i})\n\\end{align}\\]\nwhere\n\n\\(n\\) is the number of observations\n\\(X_i\\) are the ordered sample values\n\\(1_{(-\\infty ,x]}(X_{i})\\) is an indicator function (1 if \\(X_i \\leq x\\), else 0)"
  },
  {
    "objectID": "sessions/week3_lecture.html#k-s-test-two-sample-test",
    "href": "sessions/week3_lecture.html#k-s-test-two-sample-test",
    "title": "Hypothesis Testing",
    "section": "K-S test: two sample test",
    "text": "K-S test: two sample test\nFor the two-sample test:\n\\[\\begin{align}\nD_{n,m} = \\sup_x \\, | F_n(x) - G_m(x) |\n\\end{align}\\]\nwhere\n\n\\(F_n(x)\\) and \\(G_m(x)\\) are the EDFs of the two samples."
  },
  {
    "objectID": "sessions/week3_lecture.html#k-s-test-decision-rule",
    "href": "sessions/week3_lecture.html#k-s-test-decision-rule",
    "title": "Hypothesis Testing",
    "section": "K-S test: decision rule",
    "text": "K-S test: decision rule\nThe hypotheses would be:\n\\(H_0\\): the distributions are the same \\(H_1\\): the distributions differ\nLarger values of the test statistic \\(D\\) is stronger evidence against \\(H_0\\)."
  },
  {
    "objectID": "sessions/week3_lecture.html#kernel-density-estimate-kde",
    "href": "sessions/week3_lecture.html#kernel-density-estimate-kde",
    "title": "Hypothesis Testing",
    "section": "Kernel density estimate (KDE)",
    "text": "Kernel density estimate (KDE)\n\nUsed to generate a smooth PDF for a random variable dataset.\nUseful for understanding the underlying distribution of a sample .\nThink of it as getting a smooth function to describe a histogram of data.\nThere are no assumptions about the prior distribution."
  },
  {
    "objectID": "sessions/week3_lecture.html#kde-of-simulated-heights",
    "href": "sessions/week3_lecture.html#kde-of-simulated-heights",
    "title": "Hypothesis Testing",
    "section": "KDE of simulated heights",
    "text": "KDE of simulated heights\nIt’s easy to fit a KDE to data in Python:\n\nimport numpy as np\nimport pandas as pd \nfrom scipy.stats import gaussian_kde\n\n# Supposing you have some data \ndata = pd.read_csv('/path_to_data')\n\n# Kernel Density Estimation\nkde = gaussian_kde(data)\nx_vals = np.linspace(100, 200, 100)\ny_vals = kde(x_vals)"
  },
  {
    "objectID": "sessions/week3_lecture.html#kde-of-simulated-heights-1",
    "href": "sessions/week3_lecture.html#kde-of-simulated-heights-1",
    "title": "Hypothesis Testing",
    "section": "KDE of simulated heights",
    "text": "KDE of simulated heights"
  },
  {
    "objectID": "sessions/week3_lecture.html#kde-use-case",
    "href": "sessions/week3_lecture.html#kde-use-case",
    "title": "Hypothesis Testing",
    "section": "KDE use case",
    "text": "KDE use case\nNOTE: want a diagram to show this.\n\nfit the KDE to two samples\ncompare visually\ncarry out non-paremetric test - such as Kolmogorov-Smirnov"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-1-2-3",
    "href": "sessions/week3_lecture.html#example---step-1-2-3",
    "title": "Hypothesis Testing",
    "section": "Example - step 1, 2, 3",
    "text": "Example - step 1, 2, 3\nDefine the null and alternative hypothesis\n\\(H_0\\): The mean height of male and female students is the same.\n\\(H_1\\): The mean height of male and female students is different.\n\nSet your significance level\n\\(\\alpha = 0.05\\)\n\n\nIdentify the evidence\nGroup 1 – female students\n\\(\\bar{x}_1 = 170\\), \\(s_1 = 5\\), \\(n_1\\) = 95\nGroup 2 – male students\n\\(\\bar{x}_2 = 180\\), \\(s_2 = 6\\), \\(n_2\\) = 103"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-4-1",
    "href": "sessions/week3_lecture.html#example---step-4-1",
    "title": "Hypothesis Testing",
    "section": "Example - step 4",
    "text": "Example - step 4\nCalculate the p-value\n\nUse Student’s T-test: two sample\ndon’t care if students are taller or shorter - so use two-tailed test"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-4---calculation",
    "href": "sessions/week3_lecture.html#example---step-4---calculation",
    "title": "Hypothesis Testing",
    "section": "Example - step 4 - calculation",
    "text": "Example - step 4 - calculation\nNOTE: want to add how to calculate this in Python\nSubstituting values:\n\\[\\begin{align}\ns_p &= \\sqrt{\\frac{(95-1)\\cdot 5^2 + (103-1)\\cdot 6^2}{95+103-2}} \\approx 5.55\n\\end{align}\\]\nNow compute \\(t\\):\n\\[\\begin{align}\nt &= \\frac{170 - 180}{5.55 \\cdot \\sqrt{\\tfrac{1}{95} + \\tfrac{1}{103}}} \\approx -12.7\n\\end{align}\\]"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-5",
    "href": "sessions/week3_lecture.html#example---step-5",
    "title": "Hypothesis Testing",
    "section": "Example - step 5",
    "text": "Example - step 5\nCompare p-value with hypothesis level\nNow we need to compare the test statistic to the critical t-value."
  },
  {
    "objectID": "sessions/week3_lecture.html#example---step-5---calculation",
    "href": "sessions/week3_lecture.html#example---step-5---calculation",
    "title": "Hypothesis Testing",
    "section": "Example - step 5 - calculation",
    "text": "Example - step 5 - calculation\nNOTE: need to add a description of degrees of freedom\nFor Student’s T-Test we need degrees of freedom:\n\\[\\begin{align}\ndf = n_1 + n_2 - 2 = 95 + 103 - 2 = 196\n\\end{align}\\]\nThen use Python to calculate the two-tailed critical t-value at \\(\\alpha = 0.05\\).\n\nfrom scipy.stats import t\n\nalpha = 0.05\ndf = 196\n\n# two-tailed: split alpha\nt_crit = t.ppf(1 - alpha/2, df)\nprint(\"Critical t-value:\", t_crit.round(2))\n\nCritical t-value: 1.97"
  },
  {
    "objectID": "sessions/week3_lecture.html#example---conclusion",
    "href": "sessions/week3_lecture.html#example---conclusion",
    "title": "Hypothesis Testing",
    "section": "Example - conclusion",
    "text": "Example - conclusion\nTest statistic: \\(t \\approx -12.7\\).\nCritical t-value at \\(\\alpha=0.05\\): \\(t_{crit} = 1.97\\)\n\n\nSince\n\\[\\begin{align}\nt= |-12.7| \\gg 1.97= t_crit\n\\end{align}\\]\nwe reject \\(H_0\\). Male and female students have significantly different heights."
  },
  {
    "objectID": "sessions/week4.html",
    "href": "sessions/week4.html",
    "title": "Week 4",
    "section": "",
    "text": "This week will introduce some concepts from mathematics to help with understanding equations and modelling data.",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#introduction",
    "href": "sessions/week4.html#introduction",
    "title": "Week 4",
    "section": "",
    "text": "This week will introduce some concepts from mathematics to help with understanding equations and modelling data.",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#learning-objectives",
    "href": "sessions/week4.html#learning-objectives",
    "title": "Week 4",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nDefine concept of linear maps.\nCompute linear algebra equations using vectors and matrices.\n\nDescribe how linear algebra relates to solving linear regression.",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#lecture",
    "href": "sessions/week4.html#lecture",
    "title": "Week 4",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#quiz",
    "href": "sessions/week4.html#quiz",
    "title": "Week 4",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#practical",
    "href": "sessions/week4.html#practical",
    "title": "Week 4",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4.html#further-resources",
    "href": "sessions/week4.html#further-resources",
    "title": "Week 4",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 1: Basics",
      "4. Introduction to Linear Algebra"
    ]
  },
  {
    "objectID": "sessions/week4_practical.html",
    "href": "sessions/week4_practical.html",
    "title": "Practical XXX: XXX",
    "section": "",
    "text": "This week is focussed on XXX."
  },
  {
    "objectID": "sessions/week4_practical.html#to-add-a-callout-note",
    "href": "sessions/week4_practical.html#to-add-a-callout-note",
    "title": "Practical XXX: XXX",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nSuggestions for a Better Learning Experience:\n\nXXX"
  },
  {
    "objectID": "sessions/week4_practical.html#to-add-python-code-without-running-them",
    "href": "sessions/week4_practical.html#to-add-python-code-without-running-them",
    "title": "Practical XXX: XXX",
    "section": "To add Python code without running them …",
    "text": "To add Python code without running them …\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())"
  },
  {
    "objectID": "sessions/week4_practical.html#to-add-and-run-python-code",
    "href": "sessions/week4_practical.html#to-add-and-run-python-code",
    "title": "Practical XXX: XXX",
    "section": "To add and run Python code",
    "text": "To add and run Python code\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2"
  },
  {
    "objectID": "sessions/week4_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "href": "sessions/week4_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "title": "Practical XXX: XXX",
    "section": "To add a photo - replace the path. Using relative path is also okay.",
    "text": "To add a photo - replace the path. Using relative path is also okay."
  },
  {
    "objectID": "sessions/week4_practical.html#to-add-some-questions",
    "href": "sessions/week4_practical.html#to-add-some-questions",
    "title": "Practical XXX: XXX",
    "section": "To add some “questions”",
    "text": "To add some “questions”\nThe qmd file will be rendered as two files in sessions folder, including a html and ipynb format. The html file will contain both question and answer, while the ipynb file will contain only the question.\nFor the effect, please check HTML and ipynb.\n\nQuestionAnswerAnswer\n\n\nif ??\n    ??\nelse:\n    ??\n\n\n\n\n\nif 'Moscow' in ['Moscow', 'Beijing']:\n    print(\"Moscow is in the cities list.\")\nelse:\n    print(\"Moscow is not in the cities list.\")\nMoscow is in the cities list."
  },
  {
    "objectID": "sessions/week4_practical.html#youre-done",
    "href": "sessions/week4_practical.html#youre-done",
    "title": "Practical XXX: XXX",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/week6.html",
    "href": "sessions/week6.html",
    "title": "Week 6",
    "section": "",
    "text": "This week will introduce linear regression. The most useful and widely used model in all of statistics. Regression underpins more ‘advanced’ methods like machine learning, but for most situations, it is likely to be the only model you will require.\nRegression is also one of the most misused and misunderstood models in the spatial data scientist’s toolbox. Therefore, understanding the basics is absolutely fundamental. If you understand the basics, then you stand a better chance of understanding what more sophisticated methods bring to the table.\nGetting a regression model right is no more challenging than following a baking recipe - almost anyone can follow the instructions. However, like baking an amazing cake, skill, experience and understanding gained through hours of experimentation, failures, the odd amazing success and lots of perseverance are what make the difference between a great model and a soggy bottom!",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#introduction",
    "href": "sessions/week6.html#introduction",
    "title": "Week 6",
    "section": "",
    "text": "This week will introduce linear regression. The most useful and widely used model in all of statistics. Regression underpins more ‘advanced’ methods like machine learning, but for most situations, it is likely to be the only model you will require.\nRegression is also one of the most misused and misunderstood models in the spatial data scientist’s toolbox. Therefore, understanding the basics is absolutely fundamental. If you understand the basics, then you stand a better chance of understanding what more sophisticated methods bring to the table.\nGetting a regression model right is no more challenging than following a baking recipe - almost anyone can follow the instructions. However, like baking an amazing cake, skill, experience and understanding gained through hours of experimentation, failures, the odd amazing success and lots of perseverance are what make the difference between a great model and a soggy bottom!",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#learning-objectives",
    "href": "sessions/week6.html#learning-objectives",
    "title": "Week 6",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nXXX\nXXX\nXXX",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#lecture",
    "href": "sessions/week6.html#lecture",
    "title": "Week 6",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#quiz",
    "href": "sessions/week6.html#quiz",
    "title": "Week 6",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#practical",
    "href": "sessions/week6.html#practical",
    "title": "Week 6",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6.html#further-resources",
    "href": "sessions/week6.html#further-resources",
    "title": "Week 6",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "6. Introduction to Regression"
    ]
  },
  {
    "objectID": "sessions/week6_practical.html",
    "href": "sessions/week6_practical.html",
    "title": "Practical XXX: XXX",
    "section": "",
    "text": "This week is focussed on XXX."
  },
  {
    "objectID": "sessions/week6_practical.html#to-add-a-callout-note",
    "href": "sessions/week6_practical.html#to-add-a-callout-note",
    "title": "Practical XXX: XXX",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nSuggestions for a Better Learning Experience:\n\nXXX"
  },
  {
    "objectID": "sessions/week6_practical.html#to-add-python-code-without-running-them",
    "href": "sessions/week6_practical.html#to-add-python-code-without-running-them",
    "title": "Practical XXX: XXX",
    "section": "To add Python code without running them …",
    "text": "To add Python code without running them …\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())"
  },
  {
    "objectID": "sessions/week6_practical.html#to-add-and-run-python-code",
    "href": "sessions/week6_practical.html#to-add-and-run-python-code",
    "title": "Practical XXX: XXX",
    "section": "To add and run Python code",
    "text": "To add and run Python code\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2"
  },
  {
    "objectID": "sessions/week6_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "href": "sessions/week6_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "title": "Practical XXX: XXX",
    "section": "To add a photo - replace the path. Using relative path is also okay.",
    "text": "To add a photo - replace the path. Using relative path is also okay."
  },
  {
    "objectID": "sessions/week6_practical.html#to-add-some-questions",
    "href": "sessions/week6_practical.html#to-add-some-questions",
    "title": "Practical XXX: XXX",
    "section": "To add some “questions”",
    "text": "To add some “questions”\nThe qmd file will be rendered as two files in sessions folder, including a html and ipynb format. The html file will contain both question and answer, while the ipynb file will contain only the question.\nFor the effect, please check HTML and ipynb.\n\nQuestionAnswerAnswer\n\n\nif ??\n    ??\nelse:\n    ??\n\n\n\n\n\nif 'Moscow' in ['Moscow', 'Beijing']:\n    print(\"Moscow is in the cities list.\")\nelse:\n    print(\"Moscow is not in the cities list.\")\nMoscow is in the cities list."
  },
  {
    "objectID": "sessions/week6_practical.html#youre-done",
    "href": "sessions/week6_practical.html#youre-done",
    "title": "Practical XXX: XXX",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/week7_lecture.html#understanding-and-describing-data",
    "href": "sessions/week7_lecture.html#understanding-and-describing-data",
    "title": "XXX",
    "section": "Understanding and describing data",
    "text": "Understanding and describing data\n\nQuantitative research is the process of collecting and analysing numerical data to describe, model, and predict variables of interest.\nGarbage in, garbage out.\n\n\nThis lecture focuses on understanding and describing data."
  },
  {
    "objectID": "sessions/week7_lecture.html#learning-objectives",
    "href": "sessions/week7_lecture.html#learning-objectives",
    "title": "XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this lecture you should:\n\nUnderstand basic data types;\nConsider how to summarise and represent data."
  },
  {
    "objectID": "sessions/week8.html",
    "href": "sessions/week8.html",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#introduction",
    "href": "sessions/week8.html#introduction",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#learning-objectives",
    "href": "sessions/week8.html#learning-objectives",
    "title": "Week XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nXXX\nXXX\nXXX",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#lecture",
    "href": "sessions/week8.html#lecture",
    "title": "Week XXX",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#quiz",
    "href": "sessions/week8.html#quiz",
    "title": "Week XXX",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page.",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#practical",
    "href": "sessions/week8.html#practical",
    "title": "Week XXX",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8.html#further-resources",
    "href": "sessions/week8.html#further-resources",
    "title": "Week XXX",
    "section": "Further resources",
    "text": "Further resources",
    "crumbs": [
      "Part 2: Correlation and Regression",
      "8. Multilevel Regression"
    ]
  },
  {
    "objectID": "sessions/week8_practical.html",
    "href": "sessions/week8_practical.html",
    "title": "Practical XXX: XXX",
    "section": "",
    "text": "This week is focussed on XXX."
  },
  {
    "objectID": "sessions/week8_practical.html#to-add-a-callout-note",
    "href": "sessions/week8_practical.html#to-add-a-callout-note",
    "title": "Practical XXX: XXX",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nSuggestions for a Better Learning Experience:\n\nXXX"
  },
  {
    "objectID": "sessions/week8_practical.html#to-add-python-code-without-running-them",
    "href": "sessions/week8_practical.html#to-add-python-code-without-running-them",
    "title": "Practical XXX: XXX",
    "section": "To add Python code without running them …",
    "text": "To add Python code without running them …\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())"
  },
  {
    "objectID": "sessions/week8_practical.html#to-add-and-run-python-code",
    "href": "sessions/week8_practical.html#to-add-and-run-python-code",
    "title": "Practical XXX: XXX",
    "section": "To add and run Python code",
    "text": "To add and run Python code\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2"
  },
  {
    "objectID": "sessions/week8_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "href": "sessions/week8_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "title": "Practical XXX: XXX",
    "section": "To add a photo - replace the path. Using relative path is also okay.",
    "text": "To add a photo - replace the path. Using relative path is also okay."
  },
  {
    "objectID": "sessions/week8_practical.html#to-add-some-questions",
    "href": "sessions/week8_practical.html#to-add-some-questions",
    "title": "Practical XXX: XXX",
    "section": "To add some “questions”",
    "text": "To add some “questions”\nThe qmd file will be rendered as two files in sessions folder, including a html and ipynb format. The html file will contain both question and answer, while the ipynb file will contain only the question.\nFor the effect, please check HTML and ipynb.\n\nQuestionAnswerAnswer\n\n\nif ??\n    ??\nelse:\n    ??\n\n\n\n\n\nif 'Moscow' in ['Moscow', 'Beijing']:\n    print(\"Moscow is in the cities list.\")\nelse:\n    print(\"Moscow is not in the cities list.\")\nMoscow is in the cities list."
  },
  {
    "objectID": "sessions/week8_practical.html#youre-done",
    "href": "sessions/week8_practical.html#youre-done",
    "title": "Practical XXX: XXX",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  },
  {
    "objectID": "sessions/weekX.html",
    "href": "sessions/weekX.html",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX."
  },
  {
    "objectID": "sessions/weekX.html#introduction",
    "href": "sessions/weekX.html#introduction",
    "title": "Week XXX",
    "section": "",
    "text": "This week will introduce XXX."
  },
  {
    "objectID": "sessions/weekX.html#learning-objectives",
    "href": "sessions/weekX.html#learning-objectives",
    "title": "Week XXX",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of this week, you will be able to:\n\nXXX\nXXX\nXXX"
  },
  {
    "objectID": "sessions/weekX.html#lecture",
    "href": "sessions/weekX.html#lecture",
    "title": "Week XXX",
    "section": "Lecture",
    "text": "Lecture\nTo access the lecture notes: Lecture"
  },
  {
    "objectID": "sessions/weekX.html#quiz",
    "href": "sessions/weekX.html#quiz",
    "title": "Week XXX",
    "section": "Quiz",
    "text": "Quiz\nTo access the quiz on Moodle, please check Moodle page."
  },
  {
    "objectID": "sessions/weekX.html#practical",
    "href": "sessions/weekX.html#practical",
    "title": "Week XXX",
    "section": "Practical",
    "text": "Practical\n\n\n\n\n\n\nNote\n\n\n\nTo save a copy of notebook to your own GitHub Repo: follow the GitHub link, click on Raw and then Save File As... to save it to your own computer. Make sure to change the extension from .ipynb.txt (which will probably be the default) to .ipynbbefore adding the file to your GitHub repository.\n\n\nTo access the practical:\n\nPreview\nDownload"
  },
  {
    "objectID": "sessions/weekX.html#further-resources",
    "href": "sessions/weekX.html#further-resources",
    "title": "Week XXX",
    "section": "Further resources",
    "text": "Further resources"
  },
  {
    "objectID": "sessions/weekX_practical.html",
    "href": "sessions/weekX_practical.html",
    "title": "Practical XXX: XXX",
    "section": "",
    "text": "This week is focussed on XXX."
  },
  {
    "objectID": "sessions/weekX_practical.html#to-add-a-callout-note",
    "href": "sessions/weekX_practical.html#to-add-a-callout-note",
    "title": "Practical XXX: XXX",
    "section": "To add a callout-note",
    "text": "To add a callout-note\n\n\n\n\n\n\nNote\n\n\n\nSuggestions for a Better Learning Experience:\n\nXXX"
  },
  {
    "objectID": "sessions/weekX_practical.html#to-add-python-code-without-running-them",
    "href": "sessions/weekX_practical.html#to-add-python-code-without-running-them",
    "title": "Practical XXX: XXX",
    "section": "To add Python code without running them …",
    "text": "To add Python code without running them …\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())"
  },
  {
    "objectID": "sessions/weekX_practical.html#to-add-and-run-python-code",
    "href": "sessions/weekX_practical.html#to-add-and-run-python-code",
    "title": "Practical XXX: XXX",
    "section": "To add and run Python code",
    "text": "To add and run Python code\n\nimport pandas as pd\n\n# Read CSV file, skipping first 5 rows, using row 6 as header, and handling comma as thousands separator\ndf_pop = pd.read_csv(\n    'L1_data/UK_census_population.csv',\n    skiprows=5,        # Skip first 5 rows. Wnhy?\n    thousands=',',     # Interpret commas as thousands separators\n    header=0           # After skipping, the first row becomes the header\n)\n\nprint(df_pop.head())\n\n   Area code          Area name Area type  Population 2011  Population 2021  \\\n0  K04000001  England and Wales  National       56075912.0       59597542.0   \n1  E92000001            England   Country       53012456.0       56490048.0   \n2  W92000004              Wales   Country        3063456.0        3107494.0   \n3  E12000001         North East    Region        2596886.0        2647013.0   \n4  E12000002         North West    Region        7052177.0        7417397.0   \n\n   Percentage change  \n0                6.3  \n1                6.6  \n2                1.4  \n3                1.9  \n4                5.2"
  },
  {
    "objectID": "sessions/weekX_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "href": "sessions/weekX_practical.html#to-add-a-photo---replace-the-path.-using-relative-path-is-also-okay.",
    "title": "Practical XXX: XXX",
    "section": "To add a photo - replace the path. Using relative path is also okay.",
    "text": "To add a photo - replace the path. Using relative path is also okay."
  },
  {
    "objectID": "sessions/weekX_practical.html#to-add-some-questions",
    "href": "sessions/weekX_practical.html#to-add-some-questions",
    "title": "Practical XXX: XXX",
    "section": "To add some “questions”",
    "text": "To add some “questions”\nThe qmd file will be rendered as two files in sessions folder, including a html and ipynb format. The html file will contain both question and answer, while the ipynb file will contain only the question.\nFor the effect, please check HTML and ipynb.\n\nQuestionAnswerAnswer\n\n\nif ??\n    ??\nelse:\n    ??\n\n\n\n\n\nif 'Moscow' in ['Moscow', 'Beijing']:\n    print(\"Moscow is in the cities list.\")\nelse:\n    print(\"Moscow is not in the cities list.\")\nMoscow is in the cities list."
  },
  {
    "objectID": "sessions/weekX_practical.html#youre-done",
    "href": "sessions/weekX_practical.html#youre-done",
    "title": "Practical XXX: XXX",
    "section": "You’re Done!",
    "text": "You’re Done!\nCongratulations on completing the first QM practical session! If you are still working on it, take you time.\nDon’t worry about understanding every detail of the Python code — what matters most is knowing which functions to use for a specific task, like checking minimum and maximum values or generating boxplots, and knowing how to debug when it goes wrong. Remember, practice makes perfect."
  }
]